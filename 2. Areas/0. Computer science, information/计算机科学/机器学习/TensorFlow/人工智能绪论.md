>我们需要的是一台可以从经验中学习的机器。 −阿兰·图灵
# 人工智能方法
- 推理期,试图总结归纳逻辑规则,用计算机实现,开发智能系统
	- 显式的规则过于简单,难以表示复杂抽象的概念和规则
- 机器学习期,让机器自动从数据中学习规则
	- 神经网络,通过神经网络学习复杂抽象逻辑
	- 深度学习,深层神经网络
![[Pasted image 20221121162236.png]]

# 机器学习分类
- 机器学习
	- 有监督学习
		- 数据集包含样本和对应的标签,算法学习映射关系
		- 通过计算模型预测值与真实标签误差优化网络参数
			- $f_\theta : x \to y$ 
		- 方法
			- 线性回归
			- 逻辑回归
			- 支持向量机
			- 随机森林
	- 无监督学习
		- 自行发现数据模态,自身作为监督信号
		- 通过计算模型预测值与自身误差优化网络参数
			-  $f_\theta : x \to x$ 
		- 方法
			- 自编码器
			- 生成对抗网络
	- 强化学习
		- 通过与环境交互学习
		- 算法与环境交互,获取环境反馈的滞后奖励信号
		- 无法使用计算动作与正确动作之间误差优化网络
		- 方法
			- DQN,PPO

# 神经网络与深度学习

- 基于规则的系统
	- 编写显式的规则逻辑，针对特定的任务设计的，不适合其他任务 
- 传统的机器学习算法
	- 人为设计具有一定通用性的特征检测方法
		- 如 SIFT、HOG 特 征
	- 能够适合某一类的任务，具有一定的通用性
	- 但是如何设计特征方法，以及特征方法的优劣性是问题的关键
- 神经网络
	- 使人为设计特征这通过神经网络让机器自动学习完成
	- 分类
		- 浅层的神经网络的特征提取能力较为有限
		- 深层的神经网络擅长提取高层、抽象的特征，因此具有更好的性能表现
![[Pasted image 20221121164024.png]]
# 神经网络发展

## 浅层神经网络

### MP 神经元模型
- $f(x)= h(g(x))$ 
	- $g(x)=\sum_ix_i,x_i\in \{0,1\}$ 
	- 模型通过g(x)完成输出值预测
- 没有学习能力,只能完成逻辑判定

![[Pasted image 20221121193832.png]]

### 感知机 (Perceptron)
- 第一个可以自动学习权重
- 输出值o与真实值y之间的误差用于调整神经元权重参数$\{w_1,w_2,…,w_n\}$
- 人工智能第一次兴盛
![[Pasted image 20221121194240.png]]
![[Pasted image 20221121194335.png]]
![[Pasted image 20221121194343.png]]
① 图片来自 https://slideplayer.com/slide/12771753/ 
② 图片来自 https://www.glass-bead.org/article/machines-that-morph-logic/?lang=enview

### 误差反向传播算法(Back Propagation)
- 现代深度学习核心理论基础

### Hopfield 网络
- 第二次人工智能复兴
	- 卷积神经网络
	- 循环神经网络
	- 反向传播算法等算法

![[Pasted image 20221121194642.png]]

## 深度学习

### Deep Learning
逐层预训练,训练多层神经网络
优于SVM
第三次人工智能复兴

### 线性整流单元(Rectified Linear Unit,ReLU)激活函数
最广泛的激活函数

### AlexNet
8层
不逐层训练
ReLU
Dropout

之后VGG 系列、 GoogLeNet 系列、ResNet 系列、DenseNet 系列


## 无监督学习
### 生成对抗网络
通过对抗训练,学习样本的真实分布,生成逼近度较高的样本

### DQN

![[Pasted image 20221121195200.png]]

# 深度学习特点

## 数据量
- 数据集要求高
	- 带标签
- 研究数据量需求较少的算法模型

## 计算力
- 非常大,非常依赖并行加速计算设备

## 网络规模
- 不断增大,模型性能提升

## 通用智能
- 使用一个模型完成多种任务

# 深度学习应用

## 计算机视觉
- 图片识别 Image Classification
	- 输入图片数据,输出属于每个类别的概率分布
	- 常见算法
		- VGG 系列
		- Inception 系列
		- ResNet 系列
- 目标检测 Object Detection
	- 检测图片中常见物体的大致位置
	- 常见算法
		- RCNN
		- Fast RCNN
		- Faster RCNN
		- Mask RCNN
		- SSD
		- YOLO 系列
	- ![[Pasted image 20221121195827.png]]
- 语义分割 Semantic Segmentation
	- 分割识别图片中内容
	- 常见算法
		- FCN
		- U-net
		- SegNet
		- DeepLab 系列
	- ![[Pasted image 20221121200104.png]]
- 视频理解 Video Understanding
	- 视频分类,行为检测,视频主体抽取
	- 常见算法
		- C3D
		- TSN
		- DOVF
		- TS_LSTM
- 图片生成 Image Generation
	- 通过学习真实图片分布,从学习的分布中采样获得逼真度高的生成图片
	- 常见算法
		- VAE 系列
		- GAN 系列
		- ![[Pasted image 20221121200340.png]]

## 自然语言处理
- 机器翻译 Machine Translation
	- 常见算法
		- Seq2Seq
		- BERT
		- GPT
		- GPT-2
- 聊天机器人

## 强化学学习
- 虚拟游戏
	- 常用虚拟游戏平台
		- OpenAI Gym
		- OpenAI Universe
		- OpenAI Roboschool
		- DeepMind OpenSpiel
		- MuJoCo
	- 常用强化学习算法
		- DQN
		- A3C
		- A2C
		- PPO
- 机器人 Robotics
	- 机器人控制
- 自动驾驶 Autonomous Driving

# 深度学习框架

## 主流框架
- Theano
	- 最早
	- 开发效率低,编译时间长
- Scikit-learn
	- 内置常见传统机器学习算法
	- 文档案例丰富
	- 不是专门面向神经网络
	- 不支持GPU加速
- Caffe
	- 主要面向卷积神经网络
	- C++
	- 支持GPU,CPU
	- 目前融入PyTorch
- Torch
	- Lua
	- 灵活性高
- MXNet
	- 命令式,符号式编程混合
	- 灵活性高,运行速度快
	- 文档案例丰富
- PyTorch
	- 命令式编程
		- 网络搭建调试方便
- Keras
	- 基于Theano和TensorFlow
	- 提供快速训练,测试网络接口
	- 运行效率不高,灵活性一般
- TensorFlow
	- 接口设计频繁变动,功能设计重复冗余
	- 符号式开发调试困难

PyTorch和TensorFlow
- TensorFlow 完备的解决方案和用户基础
- PyTorch 精简灵活的接口,快速搭建调试网络模型

TensorFlow 和 Keras
- Keras 高层API设计规范
- TensorFlow也有,tf.keras模块,唯一高层接口

## 功能演示

### 加速计算
```
# 创建在 CPU 环境上运算的 2 个矩阵
with tf.device('/cpu:0'):
	cpu_a = tf.random.normal([1, n])
	cpu_b = tf.random.normal([n, 1])
	print(cpu_a.device, cpu_b.device) 
# 创建使用 GPU 环境运算的 2 个矩阵
with tf.device('/gpu:0'):
	gpu_a = tf.random.normal([1, n])
	gpu_b = tf.random.normal([n, 1]) 
	print(gpu_a.device, gpu_b.device)


def cpu_run():
# CPU 运算函数 with tf.device('/cpu:0'):
	c = tf.matmul(cpu_a, cpu_b)
	return c def gpu_run():
# GPU 运算函数
with tf.device('/gpu:0'):
	c = tf.matmul(gpu_a, gpu_b)
	return c
# 第一次计算需要热身，避免将初始化时间结算在内
cpu_time = timeit.timeit(cpu_run, number=10)
gpu_time = timeit.timeit(gpu_run, number=10)
print('warmup:', cpu_time, gpu_time)
# 正式计算 10 次，取平均时间
cpu_time = timeit.timeit(cpu_run, number=10)
gpu_time = timeit.timeit(gpu_run, number=10)
print('run time:', cpu_time, gpu_time)
```

### 自动梯度

考虑表达式$y=aw^2+bw+c$,求在$(a,b,c,w)=(1,2,3,4)$处导数$\frac{dy}{dw}$

$$\frac{dy}{dw}=2aw+b$$

```
import tensorflow as tf
# 创建 4 个张量，并赋值
a = tf.constant(1.)
b = tf.constant(2.)
c = tf.constant(3.)
w = tf.constant(4.)
with tf.GradientTape() as tape:
# 构建梯度环境
	tape.watch([w]) # 将 w 加入梯度跟踪列表
	# 构建计算过程，函数表达式
	y = a * w**2 + b * w + c 
	# 自动求导
	[dy_dw] = tape.gradient(y, [w])
	print(dy_dw) # 打印出导数
```

### 常用神经网络接口

# 开发环境安装