---
tags: 
UID: 20240222114700
source: null
cssclass: null
created: "2024-02-22 11:46"
updated: "2024-02-22 12:08"
date updated: 2024-02-22 11:47
---

在欧洲 5G 基础设施公私合作伙伴关系（PPP）的认证中[^e9]，边缘计算（MEC）被确认为下一代 5G 网络的关键技术。MEC 技术在车联网（IoV）中扮演着关键角色[^e7][^e10]，当前在基于 MEC 的车联网领域，学术界的研究主要聚焦于架构设计、任务卸载和资源管理方案。在基于 MEC 的 IoV 中，计算任务从移动车辆卸载到网络边缘节点，以满足对超低延迟的需求[^e8][^55][^56][^57]。其中，决定何时、是否以及卸载多少计算任务是主要技术挑战之一。在车辆边缘计算（VEC）中，任务调度成为关键问题[^e9]，其挑战在于地理差异导致边缘服务器负载不平衡。未来的发展将聚焦于系统稳定性、适应性和性能优化，以更好地满足移动用户的需求。


在移动边缘服务器和任务调度领域，面对用户高动态性和资源限制等挑战，多种技术和算法不断涌现，为创新解决方案提供了可能[^c5][^c8] [^c7]。任务卸载算法设计方面，包括自适应算法、契约理论建模和深度强化学习等方法[^61]、[^62]、[^64]、[^65]，以及模糊逻辑和机器学习，都被用于满足不同的优化目标。传统的移动边缘计算任务调度方法，如凸逼近[^61]、[^62]、博弈论[^64]、[^65]和元启发式算法[^60]、[^66]等，在大规模场景中面临搜索空间指数增长和计算负担等挑战。移动边缘计算（MEC）资源管理领域的研究主要关注考虑 MEC 服务器资源实际限制的情况[^b16][^b7] [^b13]。为克服传统方法的局限性，将多主体强化学习与反拍卖机制相结合的创新方法[^f27] [^a12]被提出，以实现最佳资源匹配并最小化整体成本。深度强化学习方法利用深度神经网络（DNNs）的强大功能[^68][^69][^71]，在处理具有连续动作空间的动态优化问题上显示出潜力。强化学习还应用于车辆云中的长期资源供应[^f27] [^a12]，以满足资源的动态需求和严格的服务质量（QoS）要求。总体而言，MEC 在移动边缘计算和车联网领域的研究和创新持续推动着技术的进步，为解决实际问题提供了多样化的解决途径[^e9]。


在物联网车辆任务调度领域，我们面临着多方面挑战，如动态性、网络不稳定性和异构资源限制等[^c5][^c8]。车辆位置、状态和可用性的变化增加了调度复杂性，因此边缘服务器的任务调度显得至关重要[^b16][^b7][^b13]。在 MEC 车联网中，车辆的高度移动性和时变性使多维资源管理更加复杂[^f27][^a12]。现有研究通常侧重于低移动性用户的多维资源管理[^a18][^a19]，但在高度移动和动态的车联网环境下，这种方法可能会受到限制。 此外，现有方法在处理延迟敏感应用和复杂任务时存在困难，并且忽视了车辆和服务器之间的连接限制。大多数现有方法仅考虑了一到两个维度的资源[^a7]，这使得它们难以直接支持高纬度资源需求，尤其是对于复杂的计算任务而言。这种情况导致了边缘服务器负载不平衡，服务质量下降。因此，我们的任务调度方法致力于克服这些限制，以更全面、灵活的方式满足多维度资源需求的计算任务[^e9]。


人工智能和强化学习可作为快速资源管理的解决方案[^a20][^a21][^a22][^a23]。先进的机器学习技术能解决高维度控制问题，而多个代理的深度强化学习技术适用于大规模场景，它将代理部署在边缘服务器上与环境进行分布式交互，降低控制成本。使用 PPO 算法，边缘服务器可自主学习和更新任务调度策略，该算法通过限制策略更新幅度提高稳定性，添加 LTSM 网络可提供时序信息并提取有用特征。我们还借鉴了反向拍卖方法，构建多拍卖组任务卸载市场，其中车辆为买方，服务器为卖方。车辆提交任务请求后，服务器通过 RL Agent 报价，车辆根据报价选择目标服务器。本文受此启发，研究使用深度 RL Agent 报价方法，实现资源合理分配，达到竞争与合作平衡，实现负载均衡。基于任务特征和服务器状态学习到的预算策略，可有效管理任务，提高用户效用、增加收入并最大化资源利用率。


本文的主要贡献概述如下：

- 完成了IoV动态网络背景下任务调度问题的建模，将提出的问题进一步制定为半马尔可夫过程, 制定了基于多主体深度强化学习和反拍卖机制的边缘服务器资源调度方法。
- 运用反拍卖方法解决IoV中动态网络背景下的任务调度问题，实现了分布式、自适应的任务调度解决方案,在促进资源合理分配, 降低车辆卸载成本。
- 利用PPO+LSTM完成单个服务器出价策略的学习，将LSTM的记忆能力用于捕捉任务调度中的时态特征和长期依赖关系, 以提高竞标过程的性能和有效性。
- 进行了模拟实验，验证了所提方法的有效性和优越性。此外，评估了强化学习和反拍卖机制的优势和适用性，并与其他基准方法进行了比较。
