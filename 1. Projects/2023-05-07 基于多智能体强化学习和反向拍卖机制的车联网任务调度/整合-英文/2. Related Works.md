## 2. Related Works


---
==这部分还未整理, 需要调整==
- 相关工作
	- 综述车联网中的任务调度方法
	- 包括传统的优化方法和基于机器学习的方法
	- 比较它们的优缺点，指出现有方法的不足之处。


为了解决车联网中的任务调度问题，许多研究者提出了各种各样的方法。这些方法可以分为两类：传统的优化方法和基于机器学习的方法。传统的优化方法通常建立一个数学模型来描述任务调度问题，然后利用一些算法来求解该模型，例如动态规划、分支定界、遗传算法等。这些方法的优点是可以保证找到最优或近似最优的解，但是也有一些缺点，例如模型假设过于简化、算法复杂度过高、对环境变化不敏感等。基于机器学习的方法则利用一些学习技术来自适应地调整任务调度策略，例如强化学习、深度神经网络、博弈论等。这些方法的优点是可以适应复杂和动态的环境，但是也有一些缺点，例如收敛速度慢、需要大量的数据和计算资源、难以保证最优性和稳定性等。
• Wu Y, Wu J, Chen L, Yan J, Luo Y. Efficient task scheduling for servers with dynamic states in vehicular edge computing. Computer Communications. 2020 Jan 15;150:245-53. 这篇文章提出了一种考虑边缘服务器动态状态的车联网任务调度方法，目标是最小化任务的响应时间和服务器的能耗。
• Hu F, Lv L, Zhang T, Shi Y. Vehicular task scheduling strategy with resource matching computing in cloud-edge collaboration. IET Collaborative Intelligent Manufacturing. 2021 Mar 18. 这篇文章提出了一种基于资源匹配度的车联网任务调度策略，目标是最小化任务的完成时间和边缘服务器的计算单元数量。
• Wang X, Wang X, Liang C, Huang C. A Survey on Mobile Edge Networks: Convergence of Computing, Caching and Communications. IEEE Access. 2017;5:6757-74. 这篇文章是一篇综述，介绍了移动边缘网络的概念、架构、应用和挑战，以及相关的计算任务调度方法。
1. https://www.sciencedirect.com/science/article/pii/S0140366419307273
2. https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cim2.12023
3. https://www.sciencedirect.com/science/article/abs/pii/S0140366419307273
• Wu Y, Wu J, Chen L, Yan J, Luo Y. Efficient task scheduling for servers with dynamic states in vehicular edge computing. Computer Communications. 2020 Jan 15;150:245-53. 这篇文章提出了一种考虑边缘服务器动态状态的车联网任务调度方法，目标是最小化任务的响应时间和服务器的能耗。该方法利用了泊松过程和马尔可夫决策过程，建立了一个双层优化模型，并设计了一种基于贪心算法和动态规划算法的启发式算法，实现了任务的有效调度。
• Hu F, Lv L, Zhang T, Shi Y. Vehicular task scheduling strategy with resource matching computing in cloud-edge collaboration. IET Collaborative Intelligent Manufacturing. 2021 Mar 18. 这篇文章提出了一种基于资源匹配度的车联网任务调度策略，目标是最小化任务的完成时间和边缘服务器的计算单元数量。该策略利用了改进的混合遗传算法，结合了计算、存储和网络带宽资源的匹配度，生成了更优的解决方案，并利用了虚拟机技术，实现了计算单元的动态分配。
• Wang X, Wang X, Liang C, Huang C. A Survey on Mobile Edge Networks: Convergence of Computing, Caching and Communications. IEEE Access. 2017;5:6757-74. 这篇文章是一篇综述，介绍了移动边缘网络的概念、架构、应用和挑战，以及相关的计算任务调度方法。该文章分析了移动边缘网络中涉及到的计算、缓存和通信三个方面的问题和解决方案，并给出了未来的研究方向和展望。
1. https://www.sciencedirect.com/science/article/pii/S0140366419307273
2. https://www.sciencedirect.com/science/article/pii/S1319157822001653
3. https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cim2.12023
• Li Y, Chen M, Wang J. Joint Computation Offloading and Resource Allocation Optimization in Vehicular Edge Computing. IEEE Transactions on Vehicular Technology. 2019 Nov 18;69(1):1048-60. 这篇文章提出了一种联合计算卸载和资源分配优化的车联网任务调度方法，目标是最小化车辆的总能耗。该方法利用了拉格朗日对偶理论和交替方向乘子法，将原问题分解为两个子问题，并设计了一种迭代算法，实现了任务的有效卸载和资源的高效分配。
• Zhang Y, Zhang J, Liu F, Guo S. Computation Offloading and Resource Allocation in Mixed Fog/Cloud Computing Systems with Min-Max Fairness Guarantee. IEEE Transactions on Communications. 2018 Apr 17;66(4):1594-609. 这篇文章提出了一种混合雾/云计算系统中的计算卸载和资源分配方法，目标是最大化系统的最小效用。该方法利用了凸优化理论和次梯度投影法，将原问题转化为一个凸优化问题，并设计了一种分布式算法，实现了任务的公平卸载和资源的均衡分配。
• Liu Y, Chen M, Guo S, Yin J. Task Offloading and Resource Allocation for Multiuser Mobile Edge Computing with Energy Harvesting Devices. IEEE Internet of Things Journal. 2019 Feb 25;6(3):4652-63. 这篇文章提出了一种考虑能量收集设备的多用户移动边缘计算中的任务卸载和资源分配方法，目标是最大化用户的总效用。该方法利用了随机优化理论和随机近似算法，将原问题转化为一个随机优化问题，并设计了一种在线算法，实现了任务的自适应卸载和资源的动态分配。
1. https://www.sciencedirect.com/science/article/pii/S0140366419307273
2. https://www.sciencedirect.com/science/article/abs/pii/S0140366419307273
3. https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cim2.12023
• Shyalika C, Silva T, Karunananda A. Reinforcement Learning in Dynamic Task Scheduling: A Review. SN Computer Science. 2020 Sep;1(5):1-9. 这篇文章是一篇综述，介绍了动态任务调度中使用强化学习的方法和应用。该文章分析了强化学习在不同领域和场景中的优势和挑战，并给出了未来的研究方向和展望。
• Jamil B, Ijaz H, Shojafar M, Munir K. IRATS: A DRL-based intelligent priority and deadline-aware online resource allocation and task scheduling algorithm in a vehicular fog network. Ad Hoc Networks. 2023 Mar 15;141:103090. 这篇文章提出了一种基于深度强化学习的智能优先级和截止时间感知的在线资源分配和任务调度算法，目标是最小化任务的等待时间和延迟。该算法利用了近端策略优化算法，将资源分配问题建模为一个马尔可夫决策过程，并设计了一种分布式算法，实现了任务的有效卸载和资源的高效分配。
• Li X, Zhang Y, Wang Y, Zhang J. Cluster-Enabled Cooperative Scheduling Based on Reinforcement Learning for Vehicular Networks. IEEE Transactions on Vehicular Technology. 2020 Oct 26;70(1):1018-30. 这篇文章提出了一种基于强化学习的车联网中的集群协作调度方法，目标是提高通信效率和可靠性。该方法利用了深度确定性策略梯度算法，将集群协作调度问题建模为一个连续动作空间的强化学习问题，并设计了一种集中式训练和分布式执行的算法，实现了任务的优化分配和通信资源的合理利用。
1. https://link.springer.com/article/10.1007/s42979-020-00326-5
2. https://www.sciencedirect.com/science/article/pii/S1570870523000100
3. https://ieeexplore.ieee.org/document/9217939

本文主要研究的问题是车联网（IoV）中的工作流调度问题，即根据车辆的计算任务需求和移动特性，在移动边缘计算（MEC）环境中有效地分配和调度车辆的计算任务，以达到优化系统性能和用户体验的目的。车联网工作流调度涉及到多个方面的问题，如任务卸载策略、资源分配算法、激励机制设计、时延分析等。近年来，随着车联网技术和移动边缘计算技术的发展，车联网工作流调度问题受到了国内外学者的广泛关注，并取得了一些研究成果。为了对本课题有一个全面的了解，我们首先回顾了国内外相关领域的研究现状，主要包括以下几个方面：传统资源调度和随机优化的分布式资源调度方法,强化学习的车联网资源调度,强化学习移动边缘计算资源调度,强化学习服务器资源调度,车联网中的拍卖机制,强化学习定价策略。

## 二、 国内外相关研究现状综述

本文主要研究的问题是车联网（IoV）中的工作流调度问题，即根据车辆的计算任务需求和移动特性，在移动边缘计算（MEC）环境中有效地分配和调度车辆的计算任务，以达到优化系统性能和用户体验的目的。车联网工作流调度涉及到多个方面的问题，如任务卸载策略、资源分配算法、激励机制设计、时延分析等。近年来，随着车联网技术和移动边缘计算技术的发展，车联网工作流调度问题受到了国内外学者的广泛关注，并取得了一些研究成果。为了对本课题有一个全面的了解，我们首先回顾了国内外相关领域的研究现状，主要包括以下几个方面：传统资源调度和随机优化的分布式资源调度方法, 强化学习的车联网资源调度, 强化学习移动边缘计算资源调度, 强化学习服务器资源调度, 车联网中的拍卖机制, 强化学习定价策略。

### (1). 传统资源调度和随机优化的分布式资源调度方法

资源调度是指在有限的资源条件下，根据任务的需求和优先级，合理地分配和利用资源，以达到最优或次优的目标。资源调度问题在各种计算系统中都广泛存在，例如云计算、边缘计算、车联网等。传统的资源调度方法通常基于确定性或随机性的模型，通过数学规划、启发式算法、元启发式算法等技术来求解。传统资源调度方法通常基于集中式的优化模型，需要预先知道系统的参数和状态信息，然而在边缘云环境中，这些信息往往是不完全或不准确的，导致资源调度效率低下。为了解决这一问题，近年来出现了一些基于随机优化的分布式资源调度方法，它们可以根据实时的反馈信息动态地调整资源分配策略。目前已有一些针对边缘云计算场景的服务迁移和负载调度方法被提出，例如：Wang 等人（2017）提出了一个联合计算卸载、资源分配和内容缓存的优化框架，并设计了一个基于 ADMM 的分布式算法来提高具有移动边缘计算的无线蜂窝网络的收益[4]。Rahul 等人（2015）通过解耦原始 MDP 并采用李雅普诺夫优化技术，提出了一种高效、鲁棒、自适应且无需统计知识的边缘云服务迁移和负载调度算法[5]。Ibrahim 等人（2019）提出了一种考虑车辆移动性和任务延迟要求的边缘计算工作负载调度方法，并通过拉格朗日松弛技术求解[6]。Zhang 等人（2022）考虑了多跳传输导向的车联网云动态工作流调度问题，提出了一种基于人工蜂群算法和贪心策略相结合的动态工作流调度方法[7]。这些方法在一些特定场景下表现出了较好的效果，但也面临着一些挑战，例如如何保证算法的收敛性和稳定性，如何平衡探索和利用之间的权衡，如何减少通信开销和计算复杂度等。

在分布式资源调度问题中，基于随机优化的方法是一种常见的解决方案。这类方法利用随机性来处理不确定性，通过迭代更新可行解来逼近最优解。然而，基于随机优化的方法也存在一些局限性，例如收敛速度慢、计算开销大、对参数敏感等。因此，近年来出现了一种新的方法，即深度强化学习。深度强化学习是一种结合了深度神经网络和强化学习的技术，可以训练神经网络来快速准确地解决多目标优化问题[8] 。相比于基于随机优化的方法，深度强化学习具有以下优势：一是能够自动学习复杂的策略函数，无需人为设计或调整参数；二是能够利用大量数据和高效算法来提高学习效率和质量；三是能够适应动态变化的环境和目标，并实现在线决策和反馈。

### (2).强化学习的车联网资源调度


强化学习是一种基于试错学习和奖励反馈的机器学习方法，它可以让智能体在与环境交互的过程中自主地学习最优或近似最优的策略。强化学习具有以下几个特点：无需事先知道系统模型和参数；能够处理部分可观测和非马尔可夫性的环境；能够适应动态变化和不确定性的环境；能够实现长期目标和多目标之间的平衡。由于这些特点，强化学习被认为是一种适合于解决车联网资源调度问题的方法。强化学习的车联网资源调度是一种利用智能体的自主学习能力，根据车辆的状态、环境的变化和奖励信号，动态优化车辆之间和基础设施之间的通信资源分配的方法。强化学习的车联网资源调度可以提高车联网的性能，如降低时延、增加吞吐量、节省能耗等。强化学习的车联网资源调度面临着多个挑战，如高维状态空间、部分可观测性、非平稳性、多目标优化等。为了解决这些挑战，一些研究者提出了基于深度神经网络、多智能体协作、知识驱动等技术的强化学习算法，并在不同的场景中进行了验证和应用，如频谱共享、信道选择、功率控制、数据传输等。例如,Liu 等人（2019）设计了两种强化学习方法来优化计算卸载和资源分配问题[9]。Liu等人（2020）提出了一种基于优先级和价值函数的任务调度算法，考虑了任务之间的依赖性[10]。Song等人（2023）提出了一种基于潜在博弈理论和联邦深度强化学习的多异构服务器边缘计算卸载方法，能够有效地满足任务车辆用户的定制化服务需求[11]。Pang等人（2020）提出了一种考虑位置隐私保护的车联网计算资源协同调度策略，利用卡尔曼滤波预测车辆间距离，采用双重深度 Q 网络优化总成本[1]。然而，强化学习的车联网资源调度问题也存在一些挑战和难点，例如如何设计合适的状态空间、动作空间和奖励函数，如何处理高维度和连续性的状态和动作，如何实现多智能体之间的协调和博弈，如何提高学习效率和泛化能力等。


### (3). 强化学习移动边缘计算资源调度

移动边缘计算是一种将云计算的功能和服务延伸到网络边缘的技术，它可以为移动用户提供低延迟、高带宽、高可靠性的计算资源和服务。移动边缘计算中的资源调度问题是指如何在有限的计算资源和网络资源下，根据用户的任务需求和服务质量要求，合理地分配和调度任务在本地执行或卸载到边缘服务器或云服务器上执行。这是一个具有多约束、多目标、动态性和不确定性的优化问题，传统的优化方法难以有效地解决。因此，一些学者尝试使用强化学习来解决移动边缘计算中的资源调度问题，并取得了一定的成果。强化学习是一种基于智能体与环境交互学习最优行为策略的机器学习方法，可以适应不确定性和动态性，并且不需要先验知识或模型。近年来出现了许多基于强化学习的 MEC 资源调度方法，接下来对其中部分进行介绍。

例如，Zheng 等人（2022）使用深度 Q 网络（DQN）或双重深度 Q 网络（DDQN）来训练移动边缘服务器上的智能体，使其能够根据自身状态和环境状态选择最优或次优的任务卸载策略[12]；Chen J 等人（2021）使用深度确定性策略梯度算法（DDPG）来训练连续动作空间下的智能体，使其能够输出最优或次优的任务卸载比例或执行速度[13]；Chen M 等利用异步优势行动者-评论者算法 (A 3 C），提出了一个基于软件定义网络和信息中心网络的动态资源分配方案，以提高车辆网络的服务质量[14]; Peng 等使用多智能体强化学习（MARL）来训练多个边缘服务器之间的智能体，使其能够协作地进行车辆关联和资源分配决策[15]；Peng 等人（2022）提出了一种基于深度强化学习和有向无环图的依赖任务卸载策略，能够在多用户多服务器边缘计算环境中，灵活地选择合适的卸载目标服务器，并有效地减少服务延迟和终端能耗[16]。然而，强化学习在移动边缘计算中的资源调度问题仍然面临着一些问题和挑战，例如如何处理状态空间和动作空间的爆炸性增长，如何平衡探索和利用之间的权衡，如何解决多智能体之间的非平稳性和通信开销等。

### (4). 强化学习服务器资源调度

服务器资源调度是指在数据中心或云平台中，根据用户或应用程序的需求和服务质量要求，合理地分配和调度服务器上的计算资源、存储资源、网络资源等。这是一个涉及到数据中心或云平台的性能、效率、成本、节能等方面的重要问题。传统的服务器资源调度方法通常基于静态规划或启发式算法等技术来求解，但这些方法往往依赖于精确的系统模型和参数，难以适应复杂多变的环境。因此，一些学者利用强化学习来解决服务器资源调度问题，并取得了一些进展。强化学习服务器资源调度（Reinforcement Learning Server Resource Scheduling）是一种利用强化学习方法来优化服务器资源分配和任务执行的技术。它可以应对服务器状态的动态变化、多用户多任务的复杂需求、网络切片和边缘计算等新型网络架构的挑战，以及可再生能源和机器学习服务等新兴应用场景的特点。强化学习服务器资源调度的目标是在保证服务质量和满足约束条件的前提下，最大化系统效率和性能，最小化系统成本和延迟。强化学习服务器资源调度涉及多个层次和方面，包括资源配置、任务卸载、任务调度、并行度配置、协商策略等。近年来，有许多研究者提出了基于深度强化学习（Deep Reinforcement Learning）的服务器资源调度方法，并在不同的场景和数据集上进行了实验验证。

例如，有些学者使用强化学习来优化虚拟机（VM）或容器（Container）在物理机上的放置策略，以提高资源利用率和节约能耗[17–19]，其中Cheng 等人（2018）提出了一个基于深度强化学习的资源配置和任务调度系统，能够有效地降低云服务提供商的数据中心能耗和电费成本，并具有高效、可扩展、自适应和快速收敛等特点[17]，Zhao 等（2021）展示了如何利用深度强化学习在混合云环境中实现自适应的多目标任务调度，以最大化可再生能源的利用率和满足截止日期约束[19]；有些学者使用强化学习来优化服务器上的任务调度策略，以提高任务的执行效率和服务质量[20–25]，例如，Wu 等人（2020）针对服务器状态动态变化导致的资源分配不均衡问题，提出了一种基于深度强化学习和马尔可夫决策过程相结合的任务调度方法[23]，Rjoub等人（2021）提出了四种基于深度学习和强化学习的调度方法，并用真实数据集进行了实验比较。实验结果表明，深度强化学习结合长短期记忆网络（DRL-LSTM）的方法在减少任务执行成本和延迟方面优于其他三种方法[25]。然而，强化学习在服务器资源调度问题中也存在一些问题和挑战，例如如何处理大规模的状态空间和动作空间，如何处理部分可观测和非马尔可夫性的环境，如何处理多目标和多约束的优化问题，如何提高算法的收敛速度和稳定性等。


### (5).车联网中的拍卖机制

拍卖机制是一种经济学中常用的激励机制，它可以实现资源或服务的有效分配和价格的公平确定。在车联网中，拍卖机制可以应用于多种场景，例如车辆之间或车辆与基础设施之间的资源或服务交易，例如频谱、缓存、计算、数据等。近年来，许多学者研究了车联网中的拍卖机制，并设计了各种拍卖模型和算法。例如，有些学者使用密封双向拍卖（SDBA）来实现车辆之间的频谱共享和交易；有些学者使用组合双向拍卖（CDBA）来实现车辆之间的缓存共享和交易；有些学者使用反向拍卖（RAM）来实现车辆与边缘服务器之间的计算任务卸载和交易；有些学者使用多属性拍卖（MAA）来实现车辆与数据提供者之间的数据获取和交易。然而，车联网中的拍卖机制也面临着一些问题和挑战，例如如何保证拍卖机制的真实性、有效性、个体合理性、社会福利最大化等性质，如何处理参与者的自私或恶意行为，如何减少拍卖过程中的计算复杂度和通信开销等。

车联网是指通过无线通信技术，实现车辆、道路、交通设施等的信息交互和资源共享的网络。车联网可以提高道路安全，优化交通管理，提升驾驶体验，促进智能出行等。在车联网中，拍卖机制是一种有效的资源分配和价格发现的方法，可以解决供需不平衡、竞争不公平、信息不对称等问题。拍卖机制可以应用于车联网中的多种场景，例如路侧单元（RSU）的接入控制、频谱资源的分配、数据服务的交易等。接下来将对部分研究进行介绍。Vishalatchi 等人（2017）介绍了云计算中的虚拟机调度问题，以及一种基于拍卖机制的禁忌搜索算法来解决它。这可以作为一个基础和背景，让读者了解云计算中的资源分配问题和拍卖机制的作用。Ding 等人（2016）从云计算转向网格计算，介绍了网格计算无线网络中的动态资源分配问题，以及一种具有预测能力和多属性特征的新颖反向在线拍卖算法来解决它。这可以展示拍卖机制在另一种计算网络中的适用性和创新性。Liwang 等人（2019）从网格计算转向车联网，介绍了车联网中存在的计算卸载、资源共享和用户自私等问题，以及一种基于 VCG 原理的反向拍卖机制来优化计算卸载决策并满足经济属性。这可以展示拍卖机制在更具挑战性和前沿性的领域中的应用和效果。Zhang 等人（2022）进一步考虑了公共区块链网络对车联网资源分配问题的影响和支持，提出了一种利用反向拍卖模型和 VCG 机制激励车辆记录驾驶数据，并使用边缘计算节点支持区块链技术的真实拍卖机制。这可以展示拍卖机制在结合其他先进技术时能够产生更高效、安全、可信等优点。

### (6).强化学习定价策略

定价策略是指在市场交易中，根据供需关系、成本收益分析、竞争对手行为等因素，确定商品或服务的价格水平和变化规律。定价策略是一种重要的市场营销手段，它可以影响消费者的购买意愿和行为，从而影响供应商的收入和利润。在车联网中，定价策略可以应用于多种场景，例如车辆之间或车辆与基础设施之间的资源或服务交易，例如频谱、缓存、计算、数据等。近年来，许多学者研究了车联网中的定价策略，并设计了各种定价模型和算法。例如，有些学者使用基于需求函数的定价策略来实现车辆之间的频谱共享和交易；有些学者使用基于成本函数的定价策略来实现车辆之间的缓存共享和交易；有些学者使用基于效用函数的定价策略来实现车辆与边缘服务器之间的计算任务卸载和交易；有些学者使用基于博弈论的定价策略来实现车辆与数据提供者之间的数据获取和交易。然而，车联网中的定价策略也存在一些问题和挑战，例如如何根据市场环境和用户行为动态地调整价格，如何平衡供应商和消费者之间的利益，如何处理多方参与者之间的竞争和合作等。

强化学习定价策略是一种利用强化学习技术来优化定价决策的方法，它可以在不依赖用户响应函数的情况下，通过不断地探索和学习找到最优的定价策略，从而实现需求响应、能耗调度、竞争优势、成本效率等目标。强化学习定价策略在金融量化、电子市场、云计算等领域有着广泛的应用和研究。接下来将对使用强化学习进行定价的部分研究进行介绍。


Kutschinski 等人（2003）研究了电子市场中多智能体强化学习定价策略，并提出了一个分布式代理平台来模拟和评估不同竞争环境下的定价效果。随后，Kim 等人（2016）将强化学习技术应用到一个不确定微网环境中，解决了动态定价和能耗调度问题。Ghasemkhani 等人（2018）提出了一种不依赖用户响应函数的定价算法，通过强化学习找到最优定价策略，实现需求响应目标。Krasheninnikova 等人（2019）将强化学习算法扩展到保险领域，使用马尔可夫决策过程来解决保险续费价格调整的多目标优化问题。Islam 等人（2022）提出了一种基于深度强化学习的 Spark 作业调度算法，考虑了多个 SLA 目标，利用了云 VM 定价模型，动态调整了资源配置，用于解决云计算中的虚拟机（VM）调度问题。

综上所述，国内外相关领域的研究现状表明，车联网中的资源调度问题是一个具有重要意义和挑战性的课题，它涉及到多种技术和方法，例如传统优化、随机优化、强化学习、拍卖机制、定价策略等。这些技术和方法在一定程度上可以解决资源调度问题，但也存在一些不足或缺陷，需要进一步的研究和改进。因此，在本文中，我们将结合反向拍卖机制和多智能体深度强化学习，提出一种新颖的车联网工作流调度方法（RAM-DRL），并对其进行理论分析和仿真验证。下面将介绍本文研究的主要内容。




[[Learning to Bid with AuctionGym]]
[[Resource Management with Deep Reinforcement Learning]]