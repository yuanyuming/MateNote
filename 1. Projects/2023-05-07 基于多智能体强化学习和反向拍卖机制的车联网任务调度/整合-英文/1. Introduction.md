---
tags:
cssclass:
source:
created: 2023-08-14 10:19
updated: 2023-09-02 19:35
---

## 1. Introduction

Recently, with the development of Internet of Things (IoT) Technologies and Information and Communication Technologies (ICT), wireless embedded sensing devices and 5G-related technologies has been brought into modern vehicles. This makes Intelligent Transport System (ITS) becomes a reality and an indispensable component of smart cities. The applications of ITS can provide driver with prior information about traffic flow which will improve road safety, traffic efficiency and driving experience.

Internet of Vehicle(IoV) as a important part of ITS provides vehicles with various perception, communication and computing capabilities, through information exchange and collaborative services between vehicles, vehicles and infrastructures, to achieve safer, more efficient and intelligent driving. However, the computing power and battery capacity of vehicles are limited and cannot meet the requirements of some complex or delay-sensitive tasks, such as autonomous driving, video analysis, personal assistant, etc.

Mobile edge computing (MEC) as a new computing paradigm, is proposed to solve the problem above, by deploying multiple MEC servers at the road edge, provides vehicles with low-latency high-bandwidth computing resources and services. Through mobile edge computing technology, vehicles can offload part or all of their tasks to MEC servers for execution, thus saving their own energy consumption and time overhead.

Computing task scheduling is an important and challenging problem in IoV, which aims to improve the performance and experience of vehicles by effectively allocating computation-intensive services to the on-board unit (OBU) or the edge server. The tasks in IoV, such as speech recognition, natural language processing, computer vision, machine learning, augmented reality, etc., have different characteristics and requirements in terms of type, size, priority, delay, energy consumption, etc. Computing task scheduling involves deciding whether to execute the task locally on the vehicle or offload it to the edge server based on these factors, as well as the status of vehicles and edge servers, such as vehicle's location, speed and server's resources, utility, etc. However, there are many challenges in performing effective task offloading and scheduling in the mobile edge computing (MEC) environment. For example, how to make task offloading decisions based on task characteristics and real-time status; how to balance the load among different MEC servers and maximize the system utility while ensuring the quality of service (QoS); and how to design a reasonable and fair incentive mechanism to encourage cooperation among servers and avoid selfish or malicious behavior.

To solve this problem, this paper proposes a vehicular network task scheduling method based on multi-agent reinforcement learning and reverse auction mechanism. This method uses a multi-agent reinforcement learning algorithm, which enables vehicles to learn and update their own task scheduling strategies autonomously based on local and global information. At the same time, this method uses a reverse auction mechanism to achieve resource allocation and price negotiation between vehicles and edge servers. This method can effectively balance the competition and cooperation between vehicles and edge servers, and improve the efficiency and fairness of the system.

In many complex dynamic optimization problems, traditional reinforcement learning methods are difficult to handle high-dimensional state and action spaces, so deep reinforcement learning (DRL) emerged. DRL is a reinforcement learning method based on neural networks and Markov decision process (MDP) models, which can enable one or more agents to interact with the environment and learn an optimal policy that can maximize their long-term rewards. When there are multiple agents in an environment, DRL becomes a multi-agent reinforcement learning (MARL) problem, which requires each agent to adjust its own policy according to its own and other agents’ behaviors, to achieve the goal of cooperation or competition. MARL methods can be divided into value-based, policy-based and actor-critic types, which use different ways to evaluate or generate policies. MARL has many advantages, such as adaptability, robustness, scalability and distributivity, etc., which can adapt to complex, dynamic and uncertain environments and improve the efficiency and stability of the system. MARL has a wide range of applications in many fields, such as robot cooperation, traffic control, power dispatching, social simulation, etc.

This paper uses multi-agent deep reinforcement learning (MADRL) to train the policy networks deployed on each MEC server, so that they can calculate the long-term reward of accepting tasks from users according to their task requirements and their own state, and bid according to the principle of maximizing reward. Compared with other machine learning methods, DRL can directly obtain feedback signals from the environment, and optimize its own behavior through continuous exploration and exploitation. DRL does not need to predefine features or labels, nor does it need a lot of prior knowledge or assumptions, making it more suitable for dealing with complex, dynamic and uncertain environments such as vehicular networks.

Auction mechanism is a common incentive mechanism in economics, which can achieve efficient allocation and fair determination of resources or services. In vehicular networks, auction mechanism can be applied to various scenarios, such as resource or service transactions between vehicles or between vehicles and infrastructure, such as spectrum, cache, computing, data, etc. Auction mechanism can be divided into forward auction and reverse auction. Forward auction is initiated by the seller, and the buyer who bids the highest gets the goods or services. Reverse auction is initiated by the buyer, and the seller who bids the lowest gets the goods or services. Reverse auction is a type of auction mechanism where there are multiple sellers and one buyer. In reverse auction, the buyer will propose a demand and invite the sellers to quote their prices. Then, the buyer will select one or more suitable sellers from the quotes according to his/her own objectives and budget, and pay them corresponding prices. Reverse auction can be divided into different types according to the number of bidders, bidding rules, bidding information and other factors. Common types of reverse auction are: ranking reverse auction, Japanese reverse auction, Dutch reverse auction, and open reverse auction. In recent years, many scholars have studied the auction mechanism in vehicular networks and designed various auction models and algorithms.

In vehicular networks, both forward and reverse auctions have their own application scenarios and advantages, but they also face some problems and challenges. Reverse auctions can motivate vehicle users to share resources or execute tasks, such as spectrum sharing, caching sharing, computing task offloading, data acquisition, etc. These services or tasks requests can be issued by the platform, or by vehicle users or edge servers to the platform. The platform can use reverse auctions to find vehicle users or servers who are willing to provide services or execute tasks at the lowest price, and sign standard contracts with them. This can save costs for the platform. Reverse auctions can also be used to allocate some social welfare tasks to vehicle users, such as traffic management, environmental monitoring, data collection, etc. The platform can publish task information in reverse auctions according to the task demand and budget, and select vehicle users who offer the lowest price and meet the criteria to execute the tasks. This can enable the platform to effectively achieve the task objectives, while also motivating vehicle users to participate in social welfare activities and receive corresponding rewards. This paper will design a reverse auction mechanism based on mechanism design theory, which is used to allocate vehicle users’ tasks to MEC servers and motivate them to provide services or execute tasks at the lowest price. In order to implement this reverse auction mechanism, this paper will also use deep reinforcement learning to train the policy network deployed on each MEC server, so that it can calculate the long-term revenue generated by accepting tasks according to the user’s task demand and its own state, and make bids to users according to the principle of revenue maximization. This can ensure the truthfulness, efficiency and individual rationality of the resource allocation process, and achieve cooperative optimization between vehicle users and MEC servers.

This paper aims to propose a vehicular network task scheduling method based on multi-agent reinforcement learning and reverse auction mechanism, which can dynamically allocate a suitable execution plan for each task according to the resource matching degree between tasks, vehicles and edge servers, and ensure the cooperation and fairness between vehicles and edge servers through incentive mechanism. This paper believes that this method can effectively improve the efficiency and performance of task scheduling, and reduce the total cost generated in the process of task execution.



---
- 引言
	- [x] 介绍车联网的背景和应用场景
	- [x] 分析车联网中的任务调度问题和挑战
	- [x] 概述基于多智能体强化学习和反向拍卖机制的解决方案
	- [ ] 阐述论文的主要贡献和创新点。


车联网（Vehicular Ad Hoc Networks, VANETs）是一种由移动车辆和固定基础设施组成的自组织网络，它可以为车辆提供智能化、安全性和高效性的服务。随着车辆计算能力和通信带宽的提高，车辆可以执行越来越多的计算密集型和数据密集型的任务，如导航、视频流、车载载娱乐等。然而，由于车辆自身资源的有限性和动态性，以及车联网环境的复杂性和不确定性，车辆往往无法满足这些任务对资源的需求。因此，任务卸载（Task Offloading）成为了一种有效的解决方案，它可以将车辆的任务迁移到更强大和稳定的边缘服务器上执行，从而节省车辆资源、降低执行延迟、提高执行效果。

任务卸载涉及到多个参与者之间的资源分配问题，即如何将车辆的任务分配给合适的边缘服务器，并使得各方都能能获得最大化的效用。为了解决这一问题，本文借借鉴了经济学中的反向拍卖（Reverse Auction）理论，提出了一种基于反向拍卖的任务卸载方法（Reverse Auction-based Task Offloading, RATO）。反向拍卖是一种一买方多卖方的拍卖形式，适用于买方市场（Buyer’s Market）的交易活动。在反向拍卖中，买方提出自己的需求和预算，卖方根据自身的成本和利润，竞争性地给出自己的报价。最终，买方选择一个或多个报价最低且满足需求的卖方进行交易。反向拍卖可以有效降低买方的采购成本，提高卖方之间的竞争力，实现资源的优化分配。



任务卸载是指将一个或多个任务从一个服务器或节点移动到另一个服务器或节点，以提高系统的性能和资源利用率。任务卸载是一种常见的系统管理问题，它涉及到如何选择合适的执行方案，以满足任务的需求和预算。为了解决这个问题，我们需要考虑任务、执行方案和执行资源之间的匹配程度，以及执行方案之间的竞争和合作程度。为了实现任务卸载，我们可以借借鉴一些先进的技术和方法，例如容器技术、微服务架构、多智能体强化学习和反向拍卖机制等。

容器技术是一种轻量级虚拟化技术，它可以将应用程序及其依赖环境打包成一个隔离且可移移移移植的单元，并通过网络进行通信。容器技术可以提高应用程序的可维护性、可扩展性、可测试性和可靠性，同时也可以降低开发成本和复杂度。

微服务架构是一种软件设计模式，它将一个复杂的应用程序拆分成多个小而而独立的服务，每个服务负责一个特定的功能或业务领域，并且可以相互通信和协作。微服务架构可以提高应用程序的灵活性、可维护性、可扩展性、可测试性和可靠性，同时也可以降低开发成本和复杂度。

多智能体强化学习是一种机器学习方法，它可以让智能体（如车辆）根据局部和全局的信息，自主地学习和更新自己的行为策略。多智能体强化学习可以提高智能体的适应性、效率、稳定性和安全性，同时也可以降低人工干预和误差。

反向拍卖机制是一种市场机制，它可以让买方（如车辆）根据自身的需求和预算，在卖方（如边缘服务器）之间进行竞争性地报价，并选择最优化的交易方案。反向拍卖机制可以提高交易效率、公平性、灵活性和稳定性，同时也可以降低交易成本和风险。

综上所述，我们认为基于多智能体强化学习和反向拍卖机制的车联网任务调度方法是一种有效且先进的方法来解决任务卸载问题。该方法利用多智能体强化学习算法，使得车辆可以根据局部和全局的信息，自主地学习和更新自己的任务调度策略。同时，该方法利用反向拍卖机制，实现了车辆和边缘服务器之间的资源分配和价格协商。该方法可以有效地平衡车辆与边缘服务器之间的竞争和合作，提高系统的效率和公平性。

任务卸载过程的表述如下：

- 首先，我们需要定义任务的属性和需求，例如任务的类型、大小、优先级、执行时间、执行资源等。
- 然后，我们需要选择一个或多个合适的执行方案，例如边缘服务器、云服务器、容器等。我们可以根据任务的属性和需求，以及执行方案的可用性、性能、成本等因素，进行匹配和评估。
- 接着，我们需要选择一个或多个合适的执行资源，例如CPU、内存、网络等。我们可以根据任务的属性和需求，以及执行资源的数量、质量、价格等因素，进行匹配和评估。
- 最后，我们需要将任务从一个执行方案移动到另一个执行方案，并将相关的执行资源分配给新的执行方案。我们可以根据任务卸载过程中可能出现的竞争和合作情况，以及反向拍卖机制中可能出现的优化和调整情况，进行动态地调整和优化。

为了实现任务卸载过程中的技术和方法，我们可以借借鉴以下几个方面：

- 容器技术：我们可以使用容器技术来打包和移动应用程序及其依赖环境，以提高应用程序的可移移植性和可扩展性。例如，我们可以使用Docker或Kubernetes等工具来创建和管理容器化应用程序，并使用容器网络或服务发现等机制来实现容器之间的通信和协作。
- 微服务架构：我们可以使用微服务架构来拆分和组合应用程序中的功能模块，以提高应用程序的灵活性和可维护性。例如，我们可以使用RESTful API或消息队列等方式来实现微服务之间的交互，并使用负载均衡或缓存等技术来实现微服务之间的分配和优化。
- 多智能体强化学习：我们可以使用多智能体强化学习来让智能体（如车辆）根据局部和全局的信息，自主地学习和更新自己的行为策略。例如，我们可以使用Q-learning或SARSA等算法来让智能体（如车辆）根据当前状态、目标状态、奖励函数等因素，选择最优化的行动，并根据反馈信息进行调整。
- 反向拍卖机制：我们可以使用反向拍卖机制来让买方（如车辆）根据自身的需求和预算，在卖方（如边缘服务器）之间进行竞争性地报价，并选择最优化的交易方案。例如，我们可以使用二分搜索或动态规划等方法来让买方（如车辆）在有限时间内找到最佳匹配，并根据市场变化进行调整。


本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文的主要贡贡献和创新点如下：

- 本文首次将反向拍卖应用于车联网中的任务卸载问题，并设计了一个基于强化学习（Reinforcement Learning, RL） 的报价策略，使得服务器能够根据任务特征和资源源状况动态地调整报价。
- 本文通过理论分析和和仿真实验，验证了本文方法的正确性和优越性，以及对车联网性能的改善效果。
- 本文开发了一个基于 Python 的开源源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。

本文主要有以下几个方面：

- 完成了对车联网环境下边缘服务器任务卸载的建模
- 设计了一种基于反向拍卖机制的资源分配
- 建立了反向拍卖机制的车联网任务调度的强化学习环境
- 提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务调度方法，结合了机器学习和博弈论的优势，实现了分布式、自适应、激励兼容的任务调度。



**本文将从以下几个方面介绍本文所提出方法：**

- **任务卸载载概述**：介绍任务卸载在车联网中的背景、意义和挑战。
- **反向拍卖卖概述**：介绍反向拍卖在经济学中的定义、特点和应用。
- **RATO方法设计**：介绍RATO方法在任务分配上如何利用反向拍卖原理进行优化。
- **RATO方法实验**：介绍RATO方法在不同场景下如何实现有效且公平地分配任务，并与其他方法进行比较。
- **结论与展望**：总结本文所提出方法在任务分配上所取得的优势，并指出未来可能存在的改进空间。


本文的结构如下：第二节介绍了相关工作；第三节介绍了问题的建模和方法的原理；第四节介绍了仿真环境的设计和参数设置；第五节介绍了实验结果和分析；第六节总结了本文的结论和展望。


## 摘要

车联网是一种将车辆与互联网相连的技术，它可以提供各种智能化的服务，如导航、娱乐、安全等。然而，车辆的计算能力和能源有限，无法满足复杂和耗时的任务的需求。为了解决这个问题，车辆可以将部分任务卸载到边缘服务器上，从而节省能耗和提高性能。然而，任务卸载的过程涉及到多个车辆和多个服务器之间的协作和竞争，如何有效地分配任务和资源，是一个具有挑战性的问题。本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文还开发了一个基于 Python 的开源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。本文通过在该环境中进行一系列的仿真实验，验证了本文方法的有效性和优越性。