---
date created: 2023-12-07 14:35
---

## 1. Introduction

With the rapid development of Internet of Things (IoT) and Information and Communication Technology (ICT), modern vehicles are undergoing a technological revolution. Internet of Vehicles (IoV), an important part of Intelligent Transportation Systems (ITS), provides real-time traffic flow information for drivers by information exchange and collaborative services between vehicles and between vehicles and infrastructure to improve road safety, traffic efficiency and driving experience. With technological advancement, vehicles can perform more computation-intensive and data-intensive tasks with limited the computing power and battery capacity, while it is hard to meet the complex or delay-sensitive task demands.[^1] To tackle the aforementioned problem, Mobile Edge Computing (MEC), as a novel method of Task scheduling in IoV, is proposed to make vehicles offload part or all their tasks to multiple MEC servers deployed at the road edge for execution. With the support of edge computing, vehicles can offload most of their tasks to edge servers for execution, which effectively expands their resource capabilities, while reducing the traffic demand of the core network. Through this way, vehicles can enhance the safety, efficiency and intelligence of driving.

[^1]:navigation, video streaming and in-vehicle entertainment.

However, unreasonable task offloading can lead to workload imbalance among edge servers, lower server revenue and user utility. Therefore, reasonable task scheduling among edge servers is crucial for optimizing the service quality with high resource efficiency. This paper studies task scheduling that selects the appropriate execution plan according to the task’s demand and budget, which can offload tasks with different characteristics and requirements from vehicles to suitable nodes, to improve user satisfaction, edge server revenue and resource utilization. Due to the high dynamics of vehicles, dynamic changes of network, timeliness and complexity of tasks, limited and heterogeneous resources, etc., task scheduling in IoV faces multiple challenges. The commonly used methods mainly include two different methods: fuzzy logic method and machine learning method. Fuzzy logic method requires predefining various fuzzy rules, which needs a lot of time and effort to design, and is also severely limited by the prior expert knowledge based on a static global perspective. Therefore, in order to reduce manual intervention, some studies attempt to use machine learning methods for workload scheduling. Machine learning method uses some learning techniques to dynamically adjust the task scheduling strategy. However, since the data set used for learning may be outdated or unable to generalize for use in new environments, adopting a reinforcement learning agent to train in a simulation environment is a suitable choice. 

This paper proposes an innovative method that combines multi-agent reinforcement learning and reverse auction mechanism for the task scheduling problem in IoV. The goal of this method is to achieve resource matching between services, vehicles and edge servers by dynamically allocating the execution plans of computation-intensive services, and to promote cooperation between vehicles and edge servers through incentive mechanism, to improve the efficiency and performance of task scheduling and reduce the total cost. 

Specifically, this paper adopts a multi-agent reinforcement learning algorithm, which enables vehicles to learn and update their task scheduling strategies autonomously according to local and global information, so as to make full use of system resources and improve execution effects. At the same time, a reverse auction mechanism is introduced, which realizes effective cooperation between vehicles and edge servers through resource allocation and price negotiation. This mechanism aims to balance competition and cooperation, improve system efficiency and fairness, and ensure reasonable resource allocation. This paper names this method as MADRL, a task scheduling method for IoV based on multi-agent deep reinforcement learning.

The main contributions of this paper are as follows:

- Apply reverse auction to the task scheduling problem in IoV, and realize distributed, adaptive and incentive-compatible task scheduling.
- Design a bidding strategy based on PPO+LSTM, which uses the memory ability of LSTM to capture the temporal characteristics and long-term dependencies of task scheduling, and improve the performance and effect of bidding strategy.
- Develop an open-source simulation environment based on Python - VehicleJobScheduling, which simulates the process of vehicle task scheduling, and provides some common evaluation indicators.
- Through simulation experiments, verify the effectiveness and superiority of the proposed method, as well as the advantages and applicability of reinforcement learning and reverse auction mechanism, and compare with other benchmark methods.

The structure of this paper is arranged as follows: Section 2 reviews the related works, Section 3 elaborates the System Model and Problem Formulation, Section 4 describes the Method of MADRL and Reverse-Auction, Section 5 shows the Performance Evaluation, Section 6 summarizes the main conclusions and future work of this paper.
