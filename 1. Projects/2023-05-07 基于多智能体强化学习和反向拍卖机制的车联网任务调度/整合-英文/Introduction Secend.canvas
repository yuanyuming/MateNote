{
	"nodes":[
		{"id":"60cf73ff2492e3e8","type":"text","text":"### Multi-Agent Reinforcement Learning Based Resource Management in MEC- and UAV-Assisted Vehicular Networks\n\nPeng, Haixia, 和Xuemin Shen. 《Multi-Agent Reinforcement Learning Based Resource Management in MEC- and UAV-Assisted Vehicular Networks》. *IEEE Journal on Selected Areas in Communications* 39, 期 1 (2021年1月): 131–41. <https://doi.org/10.1109/JSAC.2020.3036962>.\n\nConsidering the stringent delay requirements of some applications and huge latency on wireless and wired communications between a vehicle and the cloud computing server, offloading vehicles’ tasks to the cloud computing server is sometimes inapplicable [13]–[15]. Meanwhile, physically increasing the amount of onboard resources would result in a serious increase in the manufacturing cost of vehicles. The MEC server, as an extension of the cloud computing server, shifts computing and caching capabilities close to user devices [16]–[19], and allows vehicles to offload tasks to it via multiple wireless communication technologies. By saving the time consumption on communications between the MEC and the cloud computing server, the sensitive delay requirement of an offloaded task can be satisfied. However, the amount of computing/caching resources is generally preset in each MEC-mounted base station (BS) while the resource demand from vehicle users is time-varying, underused or wasted resource issues remain in the vehicular scenarios supported by only MEC-mounted BSs, especially when there exists bursty traffic caused by some social activities or events. Taking the flexibility advantage of UAVs, mounting MEC servers in UAVs can help to address the above issues by dispatching the MEC-mounted UAVs to assist the designated BSs [11], [20]. Related applications have been also considered in different projects launched by many leading companies [21].\n\nTo implement MEC- and UAV-assisted vehicular networks, many efforts have been made recently. Some of them have been focused on the deployment of MEC-mounted UAVs. For example, [22] has studied how to deploy and schedule the MEC-mounted UAVs to support vehicular applications. Resource management, as another research emphasis, has also attracted lots of attention from the existing works, where most of them adopt the optimization and reinforcement learning (RL) methods. In [12], the transmit powers of vehicles and the trajectories of UAVs have been jointly optimized to maximize the resource efficiency on MEC-mounted UAVs. In [23], a deep RL based adaptive computation offloading method has been proposed to balance the tradeoff between energy consumption and data transmission delay in an MEC-based vehicular network. In [24], a framework using MEC-mounted UAVs has been proposed to support mobile users in the extended 5G network, and an RL method is adopted to manage the resources carried by the UAV. To jointly manage the spectrum, computing, and caching resources available to an MEC-mounted BS, deep deterministic policy gradient (DDPG)- and hierarchical DDPG (HDDPG)-based schemes have been proposed in [25]. However, only vehicular networks supported either by MEC-mounted BSs or UAVs have been studied by most of the existing works. How to perform efficient resource allocation to support applications with various resource demand and heterogeneous quality-of-service (QoS) requirements in vehicular networks with MEC-mounted BSs and UAVs still needs efforts.\n\nIn this paper, we investigate multi-dimensional resource management in the MEC- and UAV-assisted vehicular networks, where MEC servers are mounted at a macro eNodeB (MeNB) and in some UAVs to provide resource access to vehicles with limited onboard resources. Inspired by existing works [23]–[26], we adopt RL methods to achieve real-time resource management in the considered scenario. Considering the sensitive delay requirements of some vehicular applications (e.g., autonomous driving) and the wireless transmission time between a UAV and a controller, installing a central controller either at the MeNB or an edge node to enable a centralized resource management scheme is infeasible sometimes. Thus, we develop a distributed cooperative scheme based on a multi-agent RL method to manage the multi-dimensional resources available to the MEC-mounted MeNB and UAVs. The main contributions of this work are summarized as follows,\n\n1. To support as many offloaded tasks as possible while satisfying their QoS requirements, we formulate an individual optimization problem to each MEC server to jointly manage the MEC-mounted MeNB’s and UAVs’ spectrum, computing, and caching resources;\n2. Because of the vehicle association pattern variables, the formulated problems are coupled with each other and non-convex. To rapidly solve these problems to satisfy the sensitive delay requirements of the offloaded tasks, we transform each formulated problem according to the main idea of RL;\n3. We convert the transformed problems as a multi-agent problem by letting each MEC server act as an agent and develop a multi-agent DDPG (MADDPG) algorithm to solve it. Through training the MADDPG model offline, the vehicle association and resource allocation decisions can be made in real time by each MEC server.\n","x":-2845,"y":52,"width":527,"height":2750},
		{"id":"1d1686ac908b30bd","type":"text","text":"\n- Traditional approaches for dynamic Joint Computation Offloading and Resource Allocation (JCORA) problems in Mobile Edge Computing (MEC) include convex approximation [5], [6], game theory [7]–[9], and metaheuristics [4], [10].\n- These methods face challenges such as exponentially increasing search space and heavy computational burdens, particularly in large-scale scenarios.\n- The use of deep reinforcement learning (DRL) to tackle JCORA problems has gained increasing research interest, leveraging the power of deep neural networks (DNNs) [3], [12]–[20].\n- Deep Deterministic Policy Gradient (DDPG) [16], [18] has shown excellent potential in dealing with dynamic optimization problems with a continuous action space.\n- More details on these approaches can be found in Section II.\n- In traditional Deep Deterministic Policy Gradient (DDPG), both the actor and critic networks rely on fully connected networks (FCNs).\n- FCNs have two significant drawbacks: a large number of trainable parameters, making training difficult and consuming computing resources, and the limitation of extracting only global discriminative state and action policy features.\n- FCNs neglect the temporal variation of task sequences, potentially overlooking useful shapelets for function approximation.\n- Additionally, in traditional DDPG, experience transitions are uniformly sampled from the replay buffer, treating all experiences equally regardless of their significance.\n- This uniform sampling approach ignores the importance of valuable experiences, often resulting in poor stability and slow convergence during training.\n- To address the drawbacks mentioned earlier, this article introduces Temporal Attentional Deterministic Policy Gradient (TADPG), an enhanced agent derived from DDPG.\n- TADPG is designed to handle the decentralized Joint Computation Offloading and Resource Allocation (JCORA) problem within a dynamic Mobile Edge Computing (MEC) environment.\n- The TADPG agent is deployed on each Mobile Device (MD), resulting in lower control costs between the MD and its corresponding MEC server.\n- This makes TADPG more suitable for large-scale scenarios compared to centralized JCORA methods.\n- The main contributions of this work can be summarized as follows.","x":-2286,"y":3441,"width":632,"height":1084,"color":"6"},
		{"id":"d1e05b13e7f28935","type":"text","text":"- **Introduction to JCORA Problems in MEC:**\n  - Traditional approaches for dynamic Joint Computation Offloading and Resource Allocation (JCORA) problems in Mobile Edge Computing (MEC) include convex approximation [5], [6], game theory [7]–[9], and metaheuristics [4], [10].\n  - These methods face challenges, such as exponentially increasing search space and heavy computational burdens, particularly in large-scale scenarios.\n\n- **Rise of Deep Reinforcement Learning (DRL) in JCORA:**\n  - The use of deep reinforcement learning (DRL) to tackle JCORA problems has gained increasing research interest, leveraging the power of deep neural networks (DNNs) [3], [12]–[20].\n  - Deep Deterministic Policy Gradient (DDPG) [16], [18] has shown excellent potential in dealing with dynamic optimization problems with a continuous action space.\n\n- **Drawbacks of Traditional DDPG and Introduction of TADPG:**\n  - In traditional Deep Deterministic Policy Gradient (DDPG), both the actor and critic networks rely on fully connected networks (FCNs).\n    - FCNs have two significant drawbacks: a large number of trainable parameters, making training difficult and consuming computing resources, and the limitation of extracting only global discriminative state and action policy features.\n    - FCNs neglect the temporal variation of task sequences, potentially overlooking useful shapelets for function approximation.\n  - Additionally, in traditional DDPG, experience transitions are uniformly sampled from the replay buffer, treating all experiences equally regardless of their significance.\n    - This uniform sampling approach ignores the importance of valuable experiences, often resulting in poor stability and slow convergence during training.\n\n- **Introduction of Temporal Attentional Deterministic Policy Gradient (TADPG):**\n  - To address the drawbacks mentioned earlier, this article introduces Temporal Attentional Deterministic Policy Gradient (TADPG), an enhanced agent derived from DDPG.\n  - TADPG is designed to handle the decentralized JCORA problem within a dynamic MEC environment.\n    - The TADPG agent is deployed on each Mobile Device (MD), resulting in lower control costs between the MD and its corresponding MEC server.\n    - This makes TADPG more suitable for large-scale scenarios compared to centralized JCORA methods.\n\n- **Main Contributions:**\n  - The main contributions of this work can be summarized as follows.","x":-1607,"y":3441,"width":781,"height":1084,"color":"5"},
		{"id":"5911a2a71cba17fe","type":"text","text":"### Deep Reinforcement Learning for Offloading and Resource Allocation in Vehicle Edge Computing and Networks\n\nLiu, Yi, Huimin Yu, Shengli Xie和Yan Zhang. 《Deep Reinforcement Learning for Offloading and Resource Allocation in Vehicle Edge Computing and Networks》. *IEEE Transactions on Vehicular Technology* 68, 期 11 (2019年11月): 11158–68. <https://doi.org/10.1109/TVT.2019.2935450>.\n\nIn MEC based IoT network, the devices can offload all/part of the computation tasks to the MEC server which can speed up the processing of the tasks and save energy for devices [15]–[17]. Then, the main technical problem becomes whether/when/how many computation tasks should be offloaded. Numerous literatures are devoted to design the optimal strategy to solve this problem under different performance requirements [18]–[21]. Considering the long-time energy efficiency while using IoT network, an efficient edge computing infrastructure is proposed in [18]. Due to stochastic task arrivals and wireless channels, congested air interface, and prohibitive feedbacks from thousands of IoT devices, authors in [19] generate asymptotically optimal schedules tolerant to out-of-date network knowledge, thereby relieving stringent requirements on feedbacks. The optimal schedule and energy efficient resource allocation policies for MEC are proposed in [20] and [21], respectively.\n\nSince the vehicle is an important type of User Equipment (UE) in IoT system, the vehicular edge computing network structure and related resource allocation methods are studied by many researchers [22]–[27]. C. Wang et al., propose a scalable SDN-enabled MEC architecture that integrates a heterogeneous vehicular network to decrease the overall delay and offload the traffic load from the backbone network [22]. To reduce both the latency and the transmission cost of the computation offloading, a cloud-based MEC offloading framework is proposed for vehicular networks in [23]. In [24], based on the MEC-assisted vehicular offloading mode, a target server selection policy is presented to improve task offloading reliability in the case of vehicular data transmission failure. Some novel MEC-based vehicular networks are proposed in [25], [26], in which the computation offloading policies are carefully designed according to different scenarios. The reinforcement learning is used for long-term resource provision in vehicular cloud to deal with dynamic demands for the resources and stringent QoS requirements [27]. However, in the existing literatures, the vehicles play the role as users in the MEC network in which the edge servers are statically deployed and may cause “service hole” due to the explosion of service requests of tremendous number of UEs.\n\nThe focus of this paper is to design a Vehicle Edge Computing (VEC) network in which the vehicles are able to provide computation services as well as the traditional edge servers. As the traditional edge server, generally connected to road side units, small-cell base stations, etc., has fixed locations, the proposed architecture can extend the computation services range and improve flexibility of the MEC network. Then, we propose an efficient computation offloading scheme for UEs while considering the delay of the computation tasks generated by UEs. Accordingly, we formulate an optimization problem to maximize the total utility of the proposed VEC network.\n\nTo solve the problem, the stochastic traffic and communication uncertainty in vehicular communication environment should be carefully addressed. The Q-learning method is one of the model-free reinforcement learning methods which are not based on the environment elements are already known [32]. Such feature makes Q-learning method suitable for solving the proposed problem in the vehicle edge computing network. The crucial part of Q-learning is to accurately and efficiently estimate the Q value, which may lead to the curse of dimensionality as the increasing of state space. Deep reinforcement learning (DRL), which approximates the Q-function by using deep neural networks, has more advantageous than Q-learning for providing greater performance and more robust learning [33]–[36]. Hence, the proposed problem is further formulated as a semi-Markov process and two reinforcement learning methods: Q-learning based method and deep reinforcement learning (DRL) method are proposed to determine the policies of computation offloading and resource allocation.\n\nIn this paper, we propose a VEC network to enhance the flexibility and scalability of the MEC based IoT system with main contributions summarized as follows:\n\n1. We propose a vehicle edge computing network architecture in which the vehicles can provide computation services for UEs as well as the traditional edge server.\n2. We propose an efficient offloading scheme for the vehicle edge computing network while considering both delay and limited computation capabilities of vehicles and edge servers. Accordingly, we formulate an optimization problem to maximize the total utility of the vehicle edge computing network.\n3. Taking into account of the stochastic traffic and uncertain communication conditions, we reformulated the proposed problem as a semi-Markov process and propose Q-learning based reinforcement learning method and DRL method to find the policies of computation offloading and resource allocation.","x":-229,"y":265,"width":527,"height":2806},
		{"id":"bdc8ca778f55da5e","type":"text","text":"### Deep Reinforcement Learning Based Resource Management for Multi-Access Edge Computing in Vehicular Networks\n\nPeng, Haixia, 和Xuemin Shen. 《Deep Reinforcement Learning Based Resource Management for Multi-Access Edge Computing in Vehicular Networks》. *IEEE Transactions on Network Science and Engineering* 7, 期 4 (2020年10月1日): 2416–28. <https://doi.org/10.1109/TNSE.2020.2978856>.\n\nTo address the challenges on implementing MEC-based vehicular networks, many research works have been performed recently, including design of architecture, task offloading scheme, resource management scheme, and so on. For example, the MEC-based hierarchical vehicular network framework, comprised of vehicle level’s on-board computing/ storing resources and server level’s resources (resources placed at the MEC and cloud-computing servers), has been investigated in [10], [12], [14]–[16]. To better manage the spectrum/computing/storing resources among and make task offloading decisions to vehicle users, task offloading and resource management schemes have been proposed in [10], [15]–[17]. Since task offloading and spectrum/computing resource allocation are coupled with each other, the objectives of the most existing works have been achieved by jointly optimizing these two parts with traditional optimization methods [10], [15]. However, only one or two dimensions of resources have been considered in most of the existing schemes, which cannot be directly adopted to support some vehicular applications where high dimensional resources are involved, such as the computing tasks generated by the leading vehicle for platoon/convoy control [7]. Moreover, there are also some works focusing on multi-dimensional resources management in the scenarios with low mobility users [18], [19]. For MEC-based vehicular networks, the computational complexity of multi-dimensional resource management problem increases due to the high vehicle mobility and time-varying demand on resources, therefore increasing the time consumption on the resource management scheme itself. Thus, it is infeasible to adopt the pure optimization approachbased schemes to achieve multi-dimensional resource management in MEC-based vehicular networks, especially for the scenarios with delay-sensitive applications. How to design practical and QoS-oriented multi-dimensional resource management schemes for the MEC-based vehicular networks still needs efforts.\n\nAs is known, artificial intelligence (AI) technology, especially reinforcement learning (RL), can be exploited to solve resource management problems quickly [20]–[23]. Q-learning [16], [24], deep Q-learning [25]–[27], actor-critic [18], [28], and other deep RL algorithms have been widely exploited for resource management in wireless communication networks. Inspired by the existing works and considering the dynamic vehicular network environment caused by high vehicle mobility and heterogeneous applications, we investigate how to exploit deep RL to jointly manage the spectrum, computing, and storing resources to support delay-sensitive applications in the MEC-based vehicular network [12] in this paper. Specifically, the main contributions of this work can be summarized as follows,\n\n1) According to the location of the MEC server, two typical multi-dimensional resource management frameworks are proposed with placing the MEC server at a macro-cell base station (MBS) and an edge node (EN), respectively. \n2) Leveraging optimization theory, optimization problems are formulated to maximize the number of offloaded tasks with satisfied QoS requirements and constrained total amounts of available spectrum, computing, and storing resources. \n3) To rapidly solve the formulated problems and obtain optimal spectrum slicing among base stations (BSs) and optimal spectrum/computing/storing allocation among vehicles, the formulated optimization problems are transformed with deep RL. \n4) A deep deterministic policy gradient (DDPG)-based algorithm is proposed to solve the transformed RL problems. As the complexity of the transformed RL problems increases with the sizes of environment state and action, a hierarchical DDPG (HDDPG)-based algorithm is developed by combining the DDPG and the hierarchical learning architecture.","x":1804,"y":415,"width":527,"height":2424},
		{"id":"405938e52d4d732c","type":"text","text":"\n![[Pasted image 20231219142015.png]]\n\n![[Pasted image 20231219142031.png]]\n","x":2423,"y":2136,"width":594,"height":1141,"color":"6"},
		{"id":"bb560557ff125046","type":"text","text":"- To address the challenges on implementing MEC-based vehicular networks, many research works have been performed recently, including:\n  - Design of architecture\n  - Task offloading scheme\n  - Resource management scheme, and so on.\n\n- For example, the MEC-based hierarchical vehicular network framework, comprised of:\n  - Vehicle level’s on-board computing/storing resources\n  - Server level’s resources (resources placed at the MEC and cloud-computing servers), has been investigated in [10], [12], [14]–[16].\n\n- To better manage the spectrum/computing/storing resources among and make task offloading decisions to vehicle users, task offloading and resource management schemes have been proposed in [10], [15]–[17].\n\n- Since task offloading and spectrum/computing resource allocation are coupled with each other, the objectives of the most existing works have been achieved by jointly optimizing these two parts with traditional optimization methods [10], [15].\n\n- However, only one or two dimensions of resources have been considered in most of the existing schemes, which cannot be directly adopted to support some vehicular applications where high dimensional resources are involved, such as the computing tasks generated by the leading vehicle for platoon/convoy control [7].\n\n- Moreover, there are also some works focusing on multi-dimensional resources management in the scenarios with low mobility users [18], [19].\n\n- For MEC-based vehicular networks, the computational complexity of multi-dimensional resource management problem increases due to the high vehicle mobility and time-varying demand on resources, therefore increasing the time consumption on the resource management scheme itself.\n\n- Thus, it is infeasible to adopt the pure optimization approach-based schemes to achieve multi-dimensional resource management in MEC-based vehicular networks, especially for the scenarios with delay-sensitive applications.\n\n- How to design practical and QoS-oriented multi-dimensional resource management schemes for the MEC-based vehicular networks still needs efforts.\n\n- As is known, artificial intelligence (AI) technology, especially reinforcement learning (RL), can be exploited to solve resource management problems quickly [20]–[23].\n\n- Q-learning [16], [24], deep Q-learning [25]–[27], actor-critic [18], [28], and other deep RL algorithms have been widely exploited for resource management in wireless communication networks.\n\n- Inspired by the existing works and considering the dynamic vehicular network environment caused by high vehicle mobility and heterogeneous applications, we investigate how to exploit deep RL to jointly manage the spectrum, computing, and storing resources to support delay-sensitive applications in the MEC-based vehicular network [12] in this paper.\n\n- Specifically, the main contributions of this work can be summarized as follows\n\n1) According to the location of the MEC server, two typical multi-dimensional resource management frameworks are proposed with placing the MEC server at a macro-cell base station (MBS) and an edge node (EN), respectively. \n2) Leveraging optimization theory, optimization problems are formulated to maximize the number of offloaded tasks with satisfied QoS requirements and constrained total amounts of available spectrum, computing, and storing resources. \n3) To rapidly solve the formulated problems and obtain optimal spectrum slicing among base stations (BSs) and optimal spectrum/computing/storing allocation among vehicles, the formulated optimization problems are transformed with deep RL. \n4) A deep deterministic policy gradient (DDPG)-based algorithm is proposed to solve the transformed RL problems. As the complexity of the transformed RL problems increases with the sizes of environment state and action, a hierarchical DDPG (HDDPG)-based algorithm is developed by combining the DDPG and the hierarchical learning architecture.\n\n","x":2435,"y":10,"width":571,"height":2026,"color":"6"},
		{"id":"6125f2c5cee62258","type":"text","text":"- **Challenges and Research Focus in MEC-Based Vehicular Networks:**\n  - Addressing challenges in implementing MEC-based vehicular networks has been a focus of recent research, covering aspects such as:\n    - Design of architecture\n    - Task offloading schemes\n    - Resource management schemes, etc.\n\n- **Hierarchical Vehicular Network Framework:**\n  - An example is the investigation of the MEC-based hierarchical vehicular network framework, which includes on-board computing/storing resources at the vehicle level and resources at the server level (MEC and cloud-computing servers) [10], [12], [14]–[16].\n\n- **Task Offloading and Resource Management Schemes:**\n  - Task offloading and resource management schemes have been proposed to manage spectrum/computing/storing resources and make task offloading decisions to vehicle users [10], [15]–[17].\n  - Existing works typically achieve objectives by jointly optimizing task offloading and spectrum/computing resource allocation using traditional optimization methods [10], [15].\n\n- **Limitations of Existing Schemes:**\n  - Most existing schemes consider only one or two dimensions of resources, which may not directly support vehicular applications with high-dimensional resources, such as computing tasks for platoon/convoy control [7].\n  - Some works focus on multi-dimensional resource management in scenarios with low mobility users [18], [19].\n\n- **Computational Complexity Challenges:**\n  - In MEC-based vehicular networks, the computational complexity of multi-dimensional resource management increases due to high vehicle mobility and time-varying demand on resources.\n  - Pure optimization approach-based schemes become infeasible, especially for scenarios with delay-sensitive applications.\n\n- **Introduction of AI, Reinforcement Learning, and Main Contributions:**\n  - Artificial intelligence (AI) technology, particularly reinforcement learning (RL), is explored as a solution for rapid resource management [20]–[23].\n  - Q-learning [16], [24], deep Q-learning [25]–[27], and actor-critic [18], [28] algorithms have been widely used for resource management in wireless communication networks.\n  - Inspired by these approaches, and considering the dynamic vehicular network environment, the paper investigates the use of deep RL to jointly manage spectrum, computing, and storing resources to support delay-sensitive applications in the MEC-based vehicular network [12].\n\n- **Main Contributions of the Paper:**\n  1. Proposal of two multi-dimensional resource management frameworks based on the MEC server's location (macro-cell base station (MBS) and edge node (EN)).\n  2. Formulation of optimization problems, leveraging optimization theory, to maximize the number of offloaded tasks with satisfied Quality of Service (QoS) requirements, and constrained total amounts of available spectrum, computing, and storing resources.\n  3. Transformation of formulated problems using deep RL to rapidly obtain optimal spectrum slicing among base stations (BSs) and optimal spectrum/computing/storing allocation among vehicles.\n  4. Introduction of a deep deterministic policy gradient (DDPG)-based algorithm to solve the transformed RL problems. A hierarchical DDPG (HDDPG)-based algorithm is developed to address the increasing complexity of the transformed RL problems.","x":2646,"y":562,"width":250,"height":60},
		{"id":"462aeef697230fbf","type":"text","text":"- **Challenges and Research Focus in MEC-Based Vehicular Networks:**\n  - Addressing challenges in implementing MEC-based vehicular networks has been a focus of recent research, covering aspects such as:\n    - Design of architecture\n    - Task offloading schemes\n    - Resource management schemes, etc.\n\n- **Hierarchical Vehicular Network Framework:**\n  - An example is the investigation of the MEC-based hierarchical vehicular network framework, which includes on-board computing/storing resources at the vehicle level and resources at the server level (MEC and cloud-computing servers) [10], [12], [14]–[16].\n\n- **Task Offloading and Resource Management Schemes:**\n  - Task offloading and resource management schemes have been proposed to manage spectrum/computing/storing resources and make task offloading decisions to vehicle users [10], [15]–[17].\n  - Existing works typically achieve objectives by jointly optimizing task offloading and spectrum/computing resource allocation using traditional optimization methods [10], [15].\n\n- **Limitations of Existing Schemes:**\n  - Most existing schemes consider only one or two dimensions of resources, which may not directly support vehicular applications with high-dimensional resources, such as computing tasks for platoon/convoy control [7].\n  - Some works focus on multi-dimensional resource management in scenarios with low mobility users [18], [19].\n\n- **Computational Complexity Challenges:**\n  - In MEC-based vehicular networks, the computational complexity of multi-dimensional resource management increases due to high vehicle mobility and time-varying demand on resources.\n  - Pure optimization approach-based schemes become infeasible, especially for scenarios with delay-sensitive applications.\n\n- **Introduction of AI, Reinforcement Learning, and Main Contributions:**\n  - Artificial intelligence (AI) technology, particularly reinforcement learning (RL), is explored as a solution for rapid resource management [20]–[23].\n  - Q-learning [16], [24], deep Q-learning [25]–[27], and actor-critic [18], [28] algorithms have been widely used for resource management in wireless communication networks.\n  - Inspired by these approaches, and considering the dynamic vehicular network environment, the paper investigates the use of deep RL to jointly manage spectrum, computing, and storing resources to support delay-sensitive applications in the MEC-based vehicular network [12].\n\n- **Main Contributions of the Paper:**\n  1. Proposal of two multi-dimensional resource management frameworks based on the MEC server's location (macro-cell base station (MBS) and edge node (EN)).\n  2. Formulation of optimization problems, leveraging optimization theory, to maximize the number of offloaded tasks with satisfied Quality of Service (QoS) requirements, and constrained total amounts of available spectrum, computing, and storing resources.\n  3. Transformation of formulated problems using deep RL to rapidly obtain optimal spectrum slicing among base stations (BSs) and optimal spectrum/computing/storing allocation among vehicles.\n  4. Introduction of a deep deterministic policy gradient (DDPG)-based algorithm to solve the transformed RL problems. A hierarchical DDPG (HDDPG)-based algorithm is developed to address the increasing complexity of the transformed RL problems.","x":3081,"y":48,"width":755,"height":1579,"color":"5"},
		{"id":"ec67400a03415c26","type":"text","text":"### DRL-Based Long-Term Resource Planning for Task Offloading Policies in Multiserver Edge Computing Networks\n\nLi, Haiyuan, Karcius Day R. Assis, Shuangyi Yan和Dimitra Simeonidou. 《DRL-Based Long-Term Resource Planning for Task Offloading Policies in Multiserver Edge Computing Networks》. *IEEE Transactions on Network and Service Management* 19, 期 4 (2022年12月): 4151–64. <https://doi.org/10.1109/TNSM.2022.3191748>.\n\nIn previous studies, some of the task offloading algorithms assumed infinite computing resources on the MEC server for offloading operations [6], [7]. However, exploding computingintensive tasks and the imbalanced request distribution are challenging the computing capability of MEC servers in bearer networks [8], [9]. The limited MEC resources require offload policies to consider long-term rewards and bring collaboration between multiple MECs. On the other side, to improve the utilization of limited MEC server resources, a large body of literature has focused on designing offloading resource management algorithms based on centralized [7], [10]–[12] and distributed approaches [8], [13], [14].\n\nAccording to the number of servers, MEC systems in the current papers are divided into single-server [13], [15]–[17] or multiple-server [9]–[11], [18], [19] systems. Meanwhile, the techniques to tackle computation offloading and resource allocation in those models are classified into optimizationbased [10], [11], [13], [19] or machined learning based [16], [17], [20], respectively.\n\nRegarding the single-server system, Lyu et al. [13]introduced a semi-distributed approach that jointly optimizes offloading decisions and resource allocation problems. With a heuristic offloading algorithm (HODA), they achieved superior system utility with an acceptable complexity of $O(K^3)$. Nevertheless, the single-server system cannot deal with the coexistence between idle and over occupied servers because of the inevitable unbalanced request distribution [21], [22]. Under the same system model, Li et al. [16] designed a centralized based DRL-based model to simultaneously resolve offloading decisions and computing resource allocations. However, excess users will cause the explosion of the action space of the DRL based algorithm, which causes the model fail to converge. In comparison, Chen et al. [7] applied multi-agent policy based DRL model that distributed the artificial intelligence (AI) agent to the edge devices to reduce the dimension of action space. However, this approach comes at the expense of complexity and might bring burdens on the devices because of their weak computing abilities.\n\nIn order to further improve the workload carrying capability of the MEC network, multiple access in RAN was introduced as a promising technology to achieve the multi-server system. Li et al. [10], Nduwayezu et al. [12] and Xue and An [11] explored the centralized joint optimization approach for the multi-access system. First fit (FF) algorithm [23] was used to select the offloading destination for the offloading requests in the network. In comparison, Apostolopoulos et al. proposed a distributed approach towards determining the optimal data oflfoading of each user within a multiple MEC servers system by non-cooperative game among the users [8]. However, their assumption that all edge devices have access to the same set of servers neglected the geographical proximity factor in practical networks. In contrast, Kan et al. [24] designed a model where edge devices can only connect to their proximate servers. The multi-server system was achieved by relaying the workload among servers via the wired interface (Mp3) which is designed and standardized for the workload transition between MEC servers by the European Telecommunications Standards Institute (ETSI) [25]. Furthermore, Qian et al. designed a distributed algorithm and a centralized online DRL-based solution for statistic and dynamic channel scenarios, respectively, which can realized the selection of access point with minimized transmission cost [14].\n\nAlthough extensive research has been carried out on the offloading management technology in single and multiple server scenarios, few studies have been reported with consideration of long-term resource balance for offloading operations. Offloading without long-term resource balance will prefer instant high reward at the expense of the resource shorting for following offloading requests.\n\nIn summary, three critical issues need to be resolved in designing efficient offloading management policies. First, the prior joint offloading algorithms in multi-server systems ignored the geographic proximity between edge devices and servers. FF-based solutions did not fundamentally deal with the unbalanced traffic distribution. Second, the possible action space explosion in DRL-based solutions remained unclear. Last but not least, the lack of consideration of long-term reward in the current studies hindered further improvement in network resource utilization. To overcome these obstacles, the main contributions of this paper are as follows:\n\nTo the best of our knowledge, this is the first time that the optimization-based method and DRL have been geared together to solve two interrelated subproblems and find the policies that maximize long-term offloading benefits. Regarding the joint solution between edge devices in one time slot, our results show that there is a great benefit in the execution time by sorting the execution order of requests and reusing the released resources for the on processing workloads. In addition, a period of continuous time slots is taken to illustrate the long-term reward of random allocation, over allocation, and three DRL-based allocation policies. We prove that over-allocation used by the prior studies can not get reliable results as it pursues higher rewards at the expense of future loss. In comparison, DRL-based algorithms can adapt to the diversity of future network states and obtain resource allocation strategies with better performance. Furthermore, of these three DRL algorithms, compared to single-agent DQN, the cooperative multi-agent model is able to more accurately account for interactions between servers on limited resources and achieve higher average rewards. In the end, the value of server cooperation is also justified.","x":3930,"y":234,"width":527,"height":3274},
		{"id":"126967b0e284f732","type":"text","text":"- In previous studies, some of the task offloading algorithms assumed infinite computing resources on the MEC server for offloading operations [6], [7].\n\n- However, exploding computing-intensive tasks and the imbalanced request distribution are challenging the computing capability of MEC servers in bearer networks [8], [9].\n\n- The limited MEC resources require offload policies to consider long-term rewards and bring collaboration between multiple MECs.\n\n- On the other side, to improve the utilization of limited MEC server resources, a large body of literature has focused on designing offloading resource management algorithms based on:\n  - Centralized approaches [7], [10]–[12]\n  - Distributed approaches [8], [13], [14].\n\n- According to the number of servers, MEC systems in the current papers are divided into:\n  - Single-server [13], [15]–[17]\n  - Multiple-server [9]–[11], [18], [19] systems.\n\n- Meanwhile, the techniques to tackle computation offloading and resource allocation in those models are classified into:\n  - Optimization-based [10], [11], [13], [19]\n  - Machine learning-based [16], [17], [20], respectively.\n\n- Regarding the single-server system, Lyu et al. [13] introduced a semi-distributed approach that jointly optimizes offloading decisions and resource allocation problems.\n\n  - With a heuristic offloading algorithm (HODA), they achieved superior system utility with an acceptable complexity of O(K^3).\n\n  - Nevertheless, the single-server system cannot deal with the coexistence between idle and over-occupied servers because of the inevitable unbalanced request distribution [21], [22].\n\n- Under the same system model, Li et al. [16] designed a centralized-based DRL-based model to simultaneously resolve offloading decisions and computing resource allocations.\n\n  - However, excess users will cause the explosion of the action space of the DRL-based algorithm, which causes the model to fail to converge.\n\n- In comparison, Chen et al. [7] applied a multi-agent policy-based DRL model that distributed the artificial intelligence (AI) agent to the edge devices to reduce the dimension of the action space.\n\n  - However, this approach comes at the expense of complexity and might bring burdens on the devices because of their weak computing abilities.\n\n- In order to further improve the workload carrying capability of the MEC network, multiple access in RAN was introduced as a promising technology to achieve the multi-server system.\n\n  - Li et al. [10], Nduwayezu et al. [12], and Xue and An [11] explored the centralized joint optimization approach for the multi-access system.\n\n  - The First Fit (FF) algorithm [23] was used to select the offloading destination for the offloading requests in the network.\n\n- In comparison, Apostolopoulos et al. proposed a distributed approach towards determining the optimal data offloading of each user within a multiple MEC servers system by non-cooperative game among the users [8].\n\n  - However, their assumption that all edge devices have access to the same set of servers neglected the geographical proximity factor in practical networks.\n\n- In contrast, Kan et al. [24] designed a model where edge devices can only connect to their proximate servers.\n\n  - The multi-server system was achieved by relaying the workload among servers via the wired interface (Mp3) designed and standardized for the workload transition between MEC servers by the European Telecommunications Standards Institute (ETSI) [25].\n\n- Furthermore, Qian et al. designed a distributed algorithm and a centralized online DRL-based solution for statistic and dynamic channel scenarios, respectively, which can realize the selection of access point with minimized transmission cost [14].\n\n- Although extensive research has been carried out on the offloading management technology in single and multiple server scenarios, few studies have been reported with consideration of long-term resource balance for offloading operations.\n\n- Offloading without long-term resource balance will prefer instant high reward at the expense of the resource shorting for following offloading requests.\n\n- In summary, three critical issues need to be resolved in designing efficient offloading management policies.\n\n  1. First, the prior joint offloading algorithms in multi-server systems ignored the geographic proximity between edge devices and servers. FF-based solutions did not fundamentally deal with the unbalanced traffic distribution.\n\n  2. Second, the possible action space explosion in DRL-based solutions remained unclear.\n\n  3. Last but not least, the lack of consideration of long-term reward in the current studies hindered further improvement in network resource utilization.\n\n- To overcome these obstacles, the main contributions of this paper are as follows:\n\n- To the best of our knowledge, this is the first time that the optimization-based method and DRL have been geared together to solve two interrelated subproblems and find the policies that maximize long-term offloading benefits.\n\n- Regarding the joint solution between edge devices in one time slot, our results show that there is a great benefit in the execution time by sorting the execution order of requests and reusing the released resources for the on-processing workloads.\n\n- In addition, a period of continuous time slots is taken to illustrate the long-term reward of random allocation, over allocation, and three DRL-based allocation policies.\n\n- We prove that over-allocation used by the prior studies cannot get reliable results as it pursues higher rewards at the expense of future loss.\n\n- In comparison, DRL-based algorithms can adapt to the diversity of future network states and obtain resource allocation strategies with better performance.\n\n- Furthermore, of these three DRL algorithms, compared to single-agent DQN, the cooperative multi-agent model is able to more accurately account for interactions between servers on limited resources and achieve higher average rewards.\n\n- In the end, the value of server cooperation is also justified.\n\n\n","x":4504,"y":234,"width":571,"height":3200,"color":"6"},
		{"id":"1ebaf5ca1336fdd6","type":"text","text":"- **Overview of Previous Studies in MEC-Based Vehicular Networks:**\n  - Some task offloading algorithms in prior studies assumed infinite computing resources on MEC servers, but the growing demand challenges the computing capability of MEC servers in bearer networks.\n\n- **Resource Management Approaches:**\n  - A substantial body of literature focuses on designing offloading resource management algorithms based on centralized and distributed approaches for both single-server and multiple-server systems.\n\n- **Challenges and Limitations in Single-Server Systems:**\n  - Challenges in single-server systems include unbalanced request distribution and difficulty in handling coexistence between idle and over-occupied servers.\n\n- **Approaches in Single-Server Systems:**\n  - Lyu et al. [13] introduced a semi-distributed approach with a heuristic offloading algorithm (HODA) achieving superior system utility with acceptable complexity.\n  - Li et al. [16] designed a centralized DRL-based model, facing challenges with the explosion of the action space.\n  - Chen et al. [7] applied a multi-agent policy-based DRL model to reduce the dimension of the action space, but this approach added complexity to devices with weak computing abilities.\n\n- **Multi-Server Systems and Resource Management Approaches:**\n  - Multiple access in Radio Access Network (RAN) is introduced to enhance the workload carrying capability of the MEC network.\n  - Centralized joint optimization approaches [10], [11], [12], and a distributed approach involving a non-cooperative game among users [8] are explored.\n\n- **Considerations in Multi-Server Systems:**\n  - Geographic proximity is considered in some models [24], [8].\n  - A model is designed where edge devices connect only to proximate servers, and a multi-server system is achieved by relaying workload among servers via a standardized wired interface (Mp3) [25].\n\n- **Distributed Algorithm and DRL-Based Solutions:**\n  - Qian et al. designed a distributed algorithm and a centralized online DRL-based solution for statistic and dynamic channel scenarios, respectively, optimizing the selection of access points with minimized transmission cost [14].\n\n- **Critical Issues and Challenges in Existing Approaches:**\n  1. Geographic proximity between edge devices and servers is often neglected, impacting traffic distribution.\n  2. DRL-based solutions may face an unclear action space explosion.\n  3. Lack of consideration for long-term resource balance hinders further improvement in network resource utilization.\n\n- **Contributions of the Paper:**\n  - First-time integration of optimization-based method and DRL to solve interrelated subproblems and maximize long-term offloading benefits.\n  - Demonstrated benefits of sorting execution order and reusing released resources in joint solutions among edge devices in one time slot.\n  - Illustration of long-term reward for various allocation policies, proving that over-allocation pursued higher rewards at the expense of future loss.\n  - Comparison of three DRL algorithms, showing that the cooperative multi-agent model achieves higher average rewards by accurately considering interactions between servers on limited resources.\n\n- **Conclusion:**\n  - The paper contributes to overcoming challenges in offloading management, introducing novel methodologies for efficient resource utilization in MEC-based vehicular networks.","x":5154,"y":238,"width":661,"height":1691,"color":"5"},
		{"id":"93ea1152bc6b1264","type":"text","text":"### Efficient Task Scheduling for Servers with Dynamic States in Vehicular Edge Computing\n\nWu, Yalan, Jigang Wu, Long Chen, Jiaquan Yan和Yuchong Luo. 《Efficient Task Scheduling for Servers with Dynamic States in Vehicular Edge Computing》. *Computer Communications* 150 (2020年1月): 245–53. <https://doi.org/10.1016/j.comcom.2019.11.019>.\n\nIn VEC, it is critical to save energy consumption and accelerate the computation process by offloading a particular task to the roadside unit (RSU) which is placed with an edge server [7]. Therefore, most existing works in VEC focus on the algorithm design of task offloading, to minimize the response time of tasks or energy consumption. Authors in [5,8] propose adaptive algorithms for task offloading to minimize the average response time of tasks. Authors in [9] propose an efficient algorithm by contract theoretical modeling to minimize the network delay. Authors in [10] propose an intelligent offloading ∗ Corresponding author. E-mail address: <asjgwucn@outlook.com> (J. Wu). system by leveraging deep reinforcement learning to maximum the total computation and communication rates. Authors in [11] propose an energy-efficient algorithm for resource allocation in VEC. In addition, the offloading algorithm is proposed to minimize the weighted sum of energy consumption and latency [12].\n\nDue to geographical difference of vehicles, the tasks are distributed in different locations. Therefore, the load of edge servers is serious unbalanced, which results in high latency of tasks and energy consumption. However, the task scheduling algorithm in edge servers is only considered in few existing works on VEC. A heuristic algorithm for energy-efficient scheduling is proposed to minimize the energy consumption [7]. A scheduling algorithm based on ant colony optimization is proposed to minimize the completion time of jobs [13]. An algorithm for partial offloading scheduling and power allocation is proposed to minimize the weighted sum of the execution delay and energy consumption in mobile edge computing [14]. Meanwhile, authors in [15] propose a task scheduling algorithm for the applications with computation intensive and time-sensitive to minimize the completion time of tasks.\n\nThe RSUs, placed with edge servers, are densely distributed in the VEC system to guarantee the quality of service. Besides, the spatial distribution of vehicles has much difference. For example, vehicles are mainly distributed in city, especially in hot spots, instead of the remote districts. Thus, the task requests are greatly varied in space. For saving energy, some RSUs switch their state into sleep state, when there are few task requests [16–19]. Authors in [20,21] propose algorithms to maximize the energy efficiency by designing the sleeping strategies for base stations. Authors in [22] propose an efficient algorithm to minimize the energy consumption by jointing the cell association and on–off scheme. Authors in [23] propose a novel user-centric energyaware mobility management scheme to minimize the delay of tasks in the mobile edge computing, in which the candidate base stations randomly switch their states between sleep and work.\n\nTo the best of our knowledge, the existing works in VEC mainly target on the area in the algorithm designing for task offloading, only a few of them investigate the algorithms for task scheduling. Meanwhile, none of the existing works in VEC consider that the edge servers may turn to sleep state in some cases. Therefore, in this paper, we investigate the problem of scheduling the tasks in VEC to minimize the response time, in the case of that the edge servers may switch their state between sleep and work according to the traffic of the requests. The contributions of this paper are summarized as follows.\n\n- We propose a novel problem of task scheduling for minimizing the total delay of tasks in VEC, with considering that the edge servers in RSUs can dynamically switch their states between sleep and work. Meanwhile, we model task requests generated by vehicles as an independent Poisson stream, and we model an edge server in the RSU as a simple M/M/1 queuing system. Besides, the proposed problem of minimizing the total delay of tasks is formulated and the NP-hardness is proved in this paper.\n- To solve the proposed problem, we contribute a greedy algorithm by carefully choosing the edge server so that the response time of the task arrived at the current time is minimum. Meanwhile, we customize a tabu search algorithm, which can successfully refine the solution generated by the greedy algorithm.\n- We also propose a deep Q-network based algorithm by utilizing the deep reinforcement learning algorithm to learn the optimal scheduling policy for minimizing the total delay of tasks, without having a priori knowledge of dynamic statistics.\n- Simulation results show that, our proposed algorithms outperform the random algorithm also proposed in this paper in terms of the total response time of tasks. Especially, the deep Q-network based algorithm performs better than the other algorithms in terms of the total response time of tasks. For example, for the case of that the maximum tolerant response time of each task is 14 s, the total response time of tasks decreases by 24.13%, 28.73% and 35.95%, compared with the customized tabu search algorithm, the greedy algorithm and the random algorithm, respectively.","x":5895,"y":465,"width":527,"height":2822},
		{"id":"f22230870406c474","type":"text","text":"- In VEC, it is critical to save energy consumption and accelerate the computation process by offloading a particular task to the roadside unit (RSU) which is placed with an edge server [7].\n\n- Therefore, most existing works in VEC focus on the algorithm design of task offloading, aiming to minimize the response time of tasks or energy consumption.\n\n- Authors in [5,8] propose adaptive algorithms for task offloading to minimize the average response time of tasks.\n\n- Authors in [9] propose an efficient algorithm by contract theoretical modeling to minimize the network delay.\n\n- Authors in [10] propose an intelligent offloading system by leveraging deep reinforcement learning to maximize the total computation and communication rates.\n\n- Authors in [11] propose an energy-efficient algorithm for resource allocation in VEC.\n\n- In addition, the offloading algorithm is proposed to minimize the weighted sum of energy consumption and latency [12].\n\n- Due to geographical differences in vehicles, the tasks are distributed in different locations. This results in a serious imbalance in the load of edge servers, leading to high latency of tasks and increased energy consumption.\n\n- However, the task scheduling algorithm in edge servers is only considered in a few existing works on VEC.\n\n- A heuristic algorithm for energy-efficient scheduling is proposed to minimize energy consumption [7].\n\n- A scheduling algorithm based on ant colony optimization is proposed to minimize the completion time of jobs [13].\n\n- An algorithm for partial offloading scheduling and power allocation is proposed to minimize the weighted sum of the execution delay and energy consumption in mobile edge computing [14].\n\n- Meanwhile, authors in [15] propose a task scheduling algorithm for applications with computation-intensive and time-sensitive requirements to minimize the completion time of tasks.\n\n- The RSUs, placed with edge servers, are densely distributed in the VEC system to guarantee the quality of service.\n\n- Besides, the spatial distribution of vehicles has much difference. For example, vehicles are mainly distributed in the city, especially in hot spots, instead of the remote districts. Thus, the task requests are greatly varied in space.\n\n- For saving energy, some RSUs switch their state into a sleep state when there are few task requests [16–19].\n\n- Authors in [20,21] propose algorithms to maximize the energy efficiency by designing sleeping strategies for base stations.\n\n- Authors in [22] propose an efficient algorithm to minimize the energy consumption by jointing the cell association and on–off scheme.\n\n- Authors in [23] propose a novel user-centric energy-aware mobility management scheme to minimize the delay of tasks in mobile edge computing, in which the candidate base stations randomly switch their states between sleep and work.\n\n- To the best of our knowledge, the existing works in VEC mainly target the algorithm designing for task offloading, with only a few investigating algorithms for task scheduling.\n\n- Meanwhile, none of the existing works in VEC consider that edge servers may turn to a sleep state in some cases.\n\n- Therefore, in this paper, we investigate the problem of scheduling tasks in VEC to minimize the response time, considering that edge servers may switch their state between sleep and work according to the traffic of the requests.\n\n- The contributions of this paper are summarized as follows:\n\n- We propose a novel problem of task scheduling for minimizing the total delay of tasks in VEC, with considering that the edge servers in RSUs can dynamically switch their states between sleep and work. Meanwhile, we model task requests generated by vehicles as an independent Poisson stream, and we model an edge server in the RSU as a simple M/M/1 queuing system. Besides, the proposed problem of minimizing the total delay of tasks is formulated and the NP-hardness is proved in this paper.\n- To solve the proposed problem, we contribute a greedy algorithm by carefully choosing the edge server so that the response time of the task arrived at the current time is minimum. Meanwhile, we customize a tabu search algorithm, which can successfully refine the solution generated by the greedy algorithm.\n- We also propose a deep Q-network based algorithm by utilizing the deep reinforcement learning algorithm to learn the optimal scheduling policy for minimizing the total delay of tasks, without having a priori knowledge of dynamic statistics.\n- Simulation results show that, our proposed algorithms outperform the random algorithm also proposed in this paper in terms of the total response time of tasks. Especially, the deep Q-network based algorithm performs better than the other algorithms in terms of the total response time of tasks. For example, for the case of that the maximum tolerant response time of each task is 14 s, the total response time of tasks decreases by 24.13%, 28.73% and 35.95%, compared with the customized tabu search algorithm, the greedy algorithm and the random algorithm, respectively.\n\n","x":6491,"y":722,"width":627,"height":2299,"color":"6"},
		{"id":"b9441fbc2f7662a2","type":"text","text":"- **Importance of Energy Efficiency and Task Offloading in VEC:**\n  - In Vehicle Edge Computing (VEC), saving energy consumption and accelerating computation through task offloading to Roadside Units (RSUs) with edge servers is critical [7].\n  - Existing works in VEC mainly focus on task offloading algorithm design to minimize response time or energy consumption.\n\n- **Task Offloading Algorithm Design:**\n  - Adaptive algorithms [5,8] aim to minimize average response time.\n  - Contract theoretical modeling [9] proposes an algorithm to minimize network delay.\n  - Deep reinforcement learning [10] maximizes computation and communication rates.\n  - Energy-efficient resource allocation algorithm [11] and algorithms minimizing the weighted sum of energy consumption and latency [12] are proposed.\n\n- **Task Scheduling Challenges in VEC:**\n  - Geographical differences in vehicle locations result in an imbalance in edge server load, leading to high latency and increased energy consumption.\n  - Few existing works consider task scheduling algorithms in VEC systems.\n\n- **Existing Task Scheduling Algorithms in VEC:**\n  - Energy-efficient scheduling algorithms [7] and those based on ant colony optimization [13] are proposed.\n  - Algorithms considering partial offloading scheduling and power allocation [14].\n  - Task scheduling algorithms for computation-intensive and time-sensitive applications [15].\n\n- **Energy Efficiency Strategies for RSUs:**\n  - RSUs switch to a sleep state during low task request periods to save energy [16–19].\n  - Algorithms designed to maximize energy efficiency by implementing sleeping strategies for base stations [20,21].\n  - Efficient algorithms minimizing energy consumption through joint cell association and on–off schemes [22].\n  - User-centric energy-aware mobility management schemes [23].\n\n- **Gap in Existing Works:**\n  - Existing works mainly focus on task offloading algorithm design, with limited attention to task scheduling.\n  - None of the works consider the possibility of edge servers transitioning to a sleep state.\n\n- **Contributions of the Paper:**\n  1. Introduction of a novel task scheduling problem in VEC, aiming to minimize total task delay, considering dynamic state switching of edge servers in RSUs.\n  2. Modeling task requests as an independent Poisson stream and edge servers as simple M/M/1 queuing systems. Formulation of the NP-hard problem of minimizing total task delay.\n  3. Proposal of a greedy algorithm for task scheduling by selecting edge servers to minimize current task response time. Introduction of a customized tabu search algorithm to refine solutions generated by the greedy algorithm.\n  4. Introduction of a deep Q-network based algorithm utilizing deep reinforcement learning to learn optimal scheduling policies without prior knowledge of dynamic statistics.\n  5. Simulation results show the superiority of proposed algorithms over a random algorithm. The deep Q-network-based algorithm outperforms others, achieving significant reductions in total task response time.","x":7214,"y":722,"width":754,"height":1453,"color":"5"},
		{"id":"8a7016c5db0d8166","type":"text","text":"\n### Dependency-Aware Task Scheduling in Vehicular Edge Computing\n\nLiu, Yujiong, Shangguang Wang, Qinglin Zhao, Shiyu Du, Ao Zhou, Xiao Ma和Fangchun Yang. 《Dependency-Aware Task Scheduling in Vehicular Edge Computing》. *IEEE Internet of Things Journal* 7, 期 6 (2020年6月): 4961–71. <https://doi.org/10.1109/JIOT.2020.2972041>.\n\n\n\nThere has been some research works on VEC. Zhang et al. [12] proposed a task offloading scheme based on the Stackelberg game theory to maximize the utilities of both vehicles and MEC servers. Zhang et al. [13] introduced an efficient predictive combination-mode offloading mechanism to reduce the offloading cost. Dai et al. [14] developed a joint optimal VEC server selection and offloading algorithm to maximize the system utility. Zhou et al. [15] proposed an energy-efficient resource allocation algorithm based on the alternating direction method of multipliers. Zhu et al. [16] developed a dynamic task allocation solution to ensure the quality of service. The prior studies assume that applications consisting of independent tasks are offloaded to RSUs for execution. However, task execution order depends on task dependency and the effect of task dependency on the execution time of applications has not been considered in the previous research works. For an augmented vehicular reality system with the following major components: object tracking, model mapping, object recognition, perspective transformation, and merging processing, there are some task dependencies among the components, e.g., only after one vehicle is tracked, the surrounding environmental model of the vehicle can be built and only after one vehicle is recognized, the process of perspective transformation and merging processing can be executed. To ensure that multiple vehicular applications can be completed in time, it is necessary to take task dependency into account for task scheduling policies design.\n\nTo overcome the above drawbacks, in this article, we consider the task dependency and the completion time constraints when scheduling tasks into multiple MEC servers. The goal of the work is to identify task scheduling decision that minimizes the average completion time of multiple applications, subject to their respective completion time constraints. We first present a VEC architecture. Then, we specify the completion time constraint of each application and the task dependency requirements of tasks. Finally, we propose an efficient task scheduling algorithm to minimize the average completion time of multiple applications.\n\nThe main contributions of this article are as follows.\n\n1. We propose a VEC architecture which consists of multiple vehicles, multiple RSUs, and multiple MEC servers. Each vehicle has a computation-intensive and delay-sensitive application. Each RSU is equipped with multiple MEC servers. Multiple vehicles can offload their computation-intensive and delay-sensitive applications to MEC servers on RSUs for execution where applications are independent of each other but tasks (belonging to the same application) have processing dependence.\n2. We formalize the task scheduling decision problem as an optimization problem which is NP-hard, and then propose an efficient multiple applications multiple tasks scheduling (MAMTS) algorithm to solve the optimization problem. Furthermore, we prioritize multiple applications to meet their respective completion time constraints and prioritize multiple tasks for satisfying their processing dependency requirements.\n3. We evaluate the proposed task scheduling algorithm with extensive simulations. The simulation results show that our proposed algorithm can significantly reduce the average completion time of multiple applications compared with benchmark algorithms.","x":3592,"y":3867,"width":527,"height":2003},
		{"id":"1dab1d1b7467470a","type":"text","text":"![[Pasted image 20231219151604.png]]","x":4189,"y":5302,"width":354,"height":580,"color":"6"},
		{"id":"e283e054643c750e","type":"text","text":"### A Collaborative Scheduling Strategy for IoV Computing Resources Considering Location Privacy Protection in Mobile Edge Computing Environment\nPang, Meiyu, Li Wang和Ningsheng Fang. 《A Collaborative Scheduling Strategy for IoV Computing Resources Considering Location Privacy Protection in Mobile Edge Computing Environment》. Journal of Cloud Computing 9, 期 1 (2020年12月): 52. https://doi.org/10.1186/s13677-020-00201-x.\n\nWith the continuous improvement of relevant standards and continuous increase of intelligent vehicles, it is foreseeable that more and more vehicles will realize network interconnection by relevant protocols in the future. With the increasing number of vehicles, road hazards have become a problem that must be faced in the development of IoV [10]. Besides, the communication transmission of vehicle safety business has higher timeliness and reliability requirements. In some application scenarios of IoV, such as automatic driving, the delay requirement even needs to be lower than 10 ms. This makes the research on the transmission strategy of IoV security services more and more important [11,12]. In the vehicle communication process based on IEEE 802.11P and LTE-V protocols, channel congestion, channel interference, shadow fading and intelligent computing processing are main factors that affect the communication performance of vehicles. How to schedule computing resources and communication resources in IoV to improve the communication performance of vehicle safety business has important research value. Besides, the proposed scheduling strategy is based on an IoV system of multi-area multi-user multi-MEC server. A vehicle distance prediction method based on Kalman filtering is proposed combined with the mobility of IoV users in this paper. Furthermore, the total cost of communication delay and energy consumption of all users is formulated as the optimization goal, the Double DQN algorithm is used to solve the optimal scheduling strategy for minimizing the total consumption cost of system.\n\n\n","x":3592,"y":6066,"width":527,"height":1208},
		{"id":"286bdbd3744bbcd2","type":"text","text":"- There have been several research works on VEC:\n  - Zhang et al. [12] proposed a task offloading scheme based on the Stackelberg game theory to maximize the utilities of both vehicles and MEC servers.\n  - Zhang et al. [13] introduced an efficient predictive combination-mode offloading mechanism to reduce the offloading cost.\n  - Dai et al. [14] developed a joint optimal VEC server selection and offloading algorithm to maximize the system utility.\n  - Zhou et al. [15] proposed an energy-efficient resource allocation algorithm based on the alternating direction method of multipliers.\n  - Zhu et al. [16] developed a dynamic task allocation solution to ensure the quality of service.\n\n- The prior studies assume that applications consisting of independent tasks are offloaded to RSUs for execution.\n\n- However, task execution order depends on task dependency, and the effect of task dependency on the execution time of applications has not been considered in the previous research works.\n\n- For an augmented vehicular reality system with the following major components: object tracking, model mapping, object recognition, perspective transformation, and merging processing, there are some task dependencies among the components.\n\n- For example, only after one vehicle is tracked, the surrounding environmental model of the vehicle can be built, and only after one vehicle is recognized, the process of perspective transformation and merging processing can be executed.\n\n- To ensure that multiple vehicular applications can be completed in time, it is necessary to take task dependency into account for task scheduling policies design.\n\n- To overcome the above drawbacks, in this article, we consider the task dependency and the completion time constraints when scheduling tasks into multiple MEC servers.\n\n- The goal of the work is to identify task scheduling decisions that minimize the average completion time of multiple applications, subject to their respective completion time constraints.\n\n- We first present a VEC architecture.\n\n- Then, we specify the completion time constraint of each application and the task dependency requirements of tasks.\n\n- Finally, we propose an efficient task scheduling algorithm to minimize the average completion time of multiple applications.\n\n- To overcome the above drawbacks, in this article, we consider the task dependency and the completion time constraints when scheduling tasks into multiple MEC servers.\n\n- The goal of the work is to identify task scheduling decisions that minimize the average completion time of multiple applications, subject to their respective completion time constraints.\n\n- We first present a VEC architecture.\n\n- Then, we specify the completion time constraint of each application and the task dependency requirements of tasks.\n\n- Finally, we propose an efficient task scheduling algorithm to minimize the average completion time of multiple applications.\n\n","x":4189,"y":3790,"width":631,"height":1403,"color":"6"},
		{"id":"7c8ebbea53acbd4d","type":"text","text":"- **Prior Research Works on VEC:**\n  - Zhang et al. [12]: Proposed a Stackelberg game theory-based task offloading scheme to maximize utilities of vehicles and MEC servers.\n  - Zhang et al. [13]: Introduced an efficient predictive combination-mode offloading mechanism to reduce offloading cost.\n  - Dai et al. [14]: Developed a joint optimal VEC server selection and offloading algorithm to maximize system utility.\n  - Zhou et al. [15]: Proposed an energy-efficient resource allocation algorithm based on the alternating direction method of multipliers.\n  - Zhu et al. [16]: Developed a dynamic task allocation solution to ensure quality of service.\n\n- **Task Dependency Considerations:**\n  - Previous studies assumed independent task offloading to RSUs for execution.\n  - Overlooked task execution order dependency and its impact on application execution time.\n\n- **Task Dependency in Augmented Vehicular Reality System:**\n  - Components: object tracking, model mapping, object recognition, perspective transformation, and merging processing.\n  - Dependencies: Vehicle tracking precedes environmental model building, and vehicle recognition precedes perspective transformation and merging processing.\n\n- **Objectives of the Article:**\n  - Consider task dependency and completion time constraints in scheduling tasks across multiple MEC servers.\n  - Goal: Identify task scheduling decisions minimizing average completion time of multiple applications while adhering to respective completion time constraints.\n\n- **Methodology:**\n  - Presentation of VEC architecture.\n  - Specification of completion time constraints for each application and task dependency requirements.\n  - Proposal of an efficient task scheduling algorithm to minimize average completion time of multiple applications.\n\n- **Key Contributions of the Article:**\n  - Integration of task dependency and completion time constraints into task scheduling for multiple MEC servers.\n  - Development of an efficient algorithm aimed at minimizing the average completion time of multiple applications.\n  - Focus on addressing drawbacks of prior research by considering dependencies and constraints in task scheduling.","x":4921,"y":3837,"width":683,"height":1250,"color":"5"},
		{"id":"5d6cf91d30077f64","type":"text","text":"- **Background** The continuous improvement of relevant standards and the increase of intelligent vehicles indicate a future where more vehicles will achieve network interconnection through relevant protocols.\n- **Challenge** With the growing number of vehicles, addressing road hazards becomes a crucial challenge in the development of the Internet of Vehicles (IoV) [10].\n\t- Vehicle safety business communication requires high timeliness and reliability, especially in scenarios like automatic driving where the delay requirement may need to be lower than 10 ms [11,12].\n\t- In the vehicle communication process based on IEEE 802.11P and LTE-V protocols, factors such as channel congestion, channel interference, shadow fading, and intelligent computing processing significantly affect communication performance.\n- **Importance** Research on the transmission strategy of IoV security services gains importance, particularly in scheduling computing and communication resources to enhance vehicle safety business communication performance [11,12].\n- **Solution** The proposed scheduling strategy is based on an IoV system with multi-area, multi-user, and multi-Mobile Edge Computing (MEC) server configuration.\n\t- A vehicle distance prediction method based on Kalman filtering is introduced, considering the mobility of IoV users.\n\t- The optimization goal is formulated as minimizing the total cost of communication delay and energy consumption for all users.\n\t- The Double Deep Q-Network (DQN) algorithm is employed to solve the optimal scheduling strategy for minimizing the total consumption cost of the system.","x":4189,"y":6142,"width":605,"height":812,"color":"6"},
		{"id":"23fd185fed78b759","type":"text","text":"- **Background:**\n  - The continuous improvement of relevant standards and the increase in intelligent vehicles point towards a future where more vehicles achieve network interconnection through relevant protocols.\n\n- **Challenge:**\n  - With the growing number of vehicles, addressing road hazards is a crucial challenge in the development of the Internet of Vehicles (IoV) [10].\n    - Vehicle safety business communication demands high timeliness and reliability, especially in scenarios like automatic driving where the delay requirement may need to be lower than 10 ms [11,12].\n    - Factors such as channel congestion, channel interference, shadow fading, and intelligent computing processing significantly affect communication performance in the vehicle communication process based on IEEE 802.11P and LTE-V protocols.\n\n- **Importance:**\n  - Research on the transmission strategy of IoV security services gains importance, particularly in scheduling computing and communication resources to enhance vehicle safety business communication performance [11,12].\n\n- **Solution:**\n  - The proposed scheduling strategy is based on an IoV system with multi-area, multi-user, and multi-Mobile Edge Computing (MEC) server configuration.\n    - Introduces a vehicle distance prediction method based on Kalman filtering, considering the mobility of IoV users.\n    - Formulates the optimization goal as minimizing the total cost of communication delay and energy consumption for all users.\n    - Employs the Double Deep Q-Network (DQN) algorithm to solve the optimal scheduling strategy for minimizing the total consumption cost of the system.","x":4852,"y":6142,"width":616,"height":1019,"color":"5"},
		{"id":"4377f960d6d505c5","type":"text","text":"### A Truthful Reverse-Auction Mechanism for Computation Offloading in Cloud-Enabled Vehicular Network\n\nLiwang, Minghui, Shijie Dai, Zhibin Gao, Yuliang Tang和Huaiyu Dai. 《A Truthful Reverse-Auction Mechanism for Computation Offloading in Cloud-Enabled Vehicular Network》. _IEEE Internet of Things Journal_ 6, 期 3 (2019年6月): 4214–27. [https://doi.org/10.1109/JIOT.2018.2875507](https://doi.org/10.1109/JIOT.2018.2875507).\n\n\nHowever, mobile edge servers may still experience signal coverage limitations and resource constraints in cases of high user density, especially during high-traffic periods. Therefore, mobile device cloud (MDC) [7], [8] technology has been applied as a strategy for offloading computation-intensive applications to nearby mobile devices with idle resources. Compared with location-fixed mobile edge clouds, the offloading scheme in an MDC environment possesses advantages of infrastructure independency and economic efficiency.\n\nIn this paper, we investigate a Vickrey–Clarke–Groves (VCG)-based reverse auction mechanism for V2V computation offloading that addresses the aforementioned issues while considering specific features such as opportunistic connections and different V2V channel conditions in cloud-enabled vehicular networks. Specifically, we envision an offloading market containing several auction groups1 with multiple buyers (service requestors) and sellers (service providers). Groups are managed by centralized brokers (RSUs) with innovative policies that can preserve truthfulness and individual rationality. This paper makes the following contributions.\n\n\n","x":-713,"y":4245,"width":527,"height":973},
		{"id":"c542af179514c130","type":"text","text":"\n- **Introduction:**\n  - Mobile edge servers face signal coverage limitations and resource constraints, especially during high user density and traffic periods.\n  - Mobile device cloud (MDC) technology is applied for offloading computation-intensive applications to nearby mobile devices with idle resources.\n  - Advantages of MDC include infrastructure independency and economic efficiency.\n- **Research Objective:**\n  - Investigating a Vickrey–Clarke–Groves (VCG)-based reverse auction mechanism for V2V computation offloading in cloud-enabled vehicular networks.\n  - Addressing issues such as signal coverage limitations, resource constraints, and specific features like opportunistic connections and different V2V channel conditions.\n- **Auction Mechanism:**\n  - Envisioning an offloading market with multiple auction groups, each containing buyers (service requestors) and sellers (service providers).\n  - Groups are managed by centralized brokers (RSUs) with innovative policies ensuring truthfulness and individual rationality.\n- **Contributions of the Paper:**\n  - Investigates VCG-based reverse auction mechanism for V2V computation offloading.\n  - Addresses issues in cloud-enabled vehicular networks, including opportunistic connections and varied V2V channel conditions.\n  - Envisions an offloading market with centralized brokers managing auction groups for economic efficiency.","x":-94,"y":3657,"width":591,"height":898,"color":"6"},
		{"id":"756c3e54b6e06e7e","type":"text","text":"\n![[Pasted image 20231219141124.png]]\nTABLE II OPTIMAL VCG-BASED REVERSE AUCTION\n\n![[Pasted image 20231219141141.png]]\nTABLE III PROPOSED MAT C H I N G ALGORITHM IN REVERSE AUCTION","x":-94,"y":4600,"width":591,"height":988,"color":"6"},
		{"id":"c58793506f600720","type":"text","text":"- **Introduction:**\n  - Mobile edge servers face signal coverage limitations and resource constraints, especially during high user density and traffic periods.\n  - Mobile device cloud (MDC) technology is applied for offloading computation-intensive applications to nearby mobile devices with idle resources.\n  - Advantages of MDC include infrastructure independency and economic efficiency.\n\n- **Research Objective:**\n  - Investigating a Vickrey–Clarke–Groves (VCG)-based reverse auction mechanism for V2V computation offloading in cloud-enabled vehicular networks.\n  - Addressing issues such as signal coverage limitations, resource constraints, and specific features like opportunistic connections and different V2V channel conditions.\n\n- **Auction Mechanism:**\n  - Envisioning an offloading market with multiple auction groups, each containing buyers (service requestors) and sellers (service providers).\n  - Groups are managed by centralized brokers (RSUs) with innovative policies ensuring truthfulness and individual rationality.\n\n- **Contributions of the Paper:**\n  - Investigates VCG-based reverse auction mechanism for V2V computation offloading.\n  - Addresses issues in cloud-enabled vehicular networks, including opportunistic connections and varied V2V channel conditions.\n  - Envisions an offloading market with centralized brokers managing auction groups for economic efficiency.","x":546,"y":3657,"width":614,"height":846,"color":"5"},
		{"id":"48d95710b6d6f974","type":"text","text":"- MEC can effectively reduce the delay cost of service delivery and network operation by deploying servers close to mobile users.\n\n- It has been certified by the European 5G Infrastructure Public Private Partnership (PPP) as one of the key technologies of the next-generation 5G network.\n\n- The advantages of MEC include:\n  - Low latency\n  - High bandwidth\n  - Real-time wireless network information\n  - Location awareness [7,8].\n\n- The MEC-based Internet of Vehicles (IoV) allows mobile vehicles to offload computing tasks to network edge nodes for processing, helping to achieve the ultra-low latency requirements of IoV [9].\n\n- MEC sinks cloud services to the edge of the wireless access network and provides computing services near moving vehicles [10].\n\n- However, in the MEC-based vehicle-connected network, there are various computationally intensive and delay-sensitive computational tasks.\n\n- Each task has different resource requirements, including:\n  - Computing resources required for task execution\n  - Communication resources required for task transmission.\n\n- In this case, a suitable strategy is needed to control offloading tasks and ensure the normal operation of the system.\n\n- Considering the impact of offloading decision and resource allocation on computing offloading performance.\n\n- In response to the above problems, a computing offloading resource allocation scheme using reinforcement learning in a MEC system is proposed.\n","x":1977,"y":4457,"width":641,"height":824,"color":"6"},
		{"id":"df604f2483501e93","type":"text","text":"- **Introduction to MEC and its Certification:**\n  - MEC is effective in reducing service delivery and network operation delay costs by deploying servers close to mobile users.\n  - Certified by the European 5G Infrastructure Public Private Partnership (PPP) as a key technology for the next-generation 5G network.\n\n- **Advantages of MEC:**\n  - Low latency\n  - High bandwidth\n  - Real-time wireless network information\n  - Location awareness [7,8].\n\n- **MEC-Based Internet of Vehicles (IoV):**\n  - MEC facilitates the offloading of computing tasks from mobile vehicles to network edge nodes, addressing ultra-low latency requirements of IoV [9].\n  - It sinks cloud services to the edge of the wireless access network, providing computing services near moving vehicles [10].\n\n- **Challenges in MEC-Based Vehicle-Connected Networks:**\n  - In MEC-based vehicle-connected networks, various computationally intensive and delay-sensitive tasks exist.\n  - Each task has distinct resource requirements, encompassing computing and communication resources.\n\n- **Need for Offloading Strategy and Resource Control:**\n  - A suitable strategy is required to control offloading tasks, ensuring the normal operation of the system.\n  - Considering the impact of offloading decisions and resource allocation on computing offloading performance.\n\n- **Proposed Solution:**\n  - In response to the mentioned challenges, a computing offloading resource allocation scheme is proposed.\n  - The scheme utilizes reinforcement learning in a MEC system to optimize the offloading decisions and resource allocation, addressing the dynamic and diverse nature of the tasks and resource requirements.","x":2662,"y":4308,"width":689,"height":991,"color":"5"},
		{"id":"59e271b6d698153c","type":"text","text":"### A Computing Offloading Resource Allocation Scheme Using Deep Reinforcement Learning in Mobile Edge Computing Systems\n\nLi, Xuezhu. 《A Computing Offloading Resource Allocation Scheme Using Deep Reinforcement Learning in Mobile Edge Computing Systems》. _Journal of Grid Computing_ 19, 期 3 (2021年9月): 35. [https://doi.org/10.1007/s10723-021-09568-w](https://doi.org/10.1007/s10723-021-09568-w).\n\nMEC can effectively reduce the delay cost of service delivery and network operation by deploying servers close to mobile users. And it has been certified by European 5G Infrastructure Public Private Partnership (PPP) as one of key technologies of the next-generation 5G network. The advantages of MEC include low latency, high bandwidth, real time wireless network information and location awareness [7,8]. The MEC-based Internet of Vehicles (IoV) allows mobile vehicles to offload computing tasks to network edge nodes for processing, which helps to achieve the ultra-low latency requirements of IoV [9]. MEC sinks cloud services to the edge of wireless access network and provides computing services near moving vehicles [10]. However, in the MEC-based vehicle-connected network, there are various computationally intensive and delay sensitive computational tasks. Moreover, each task has different resource requirements, including computing resources required for task execution and communication resources required for task transmission. In this case, a suitable strategy is needed to control offloading tasks and ensure the normal operation of system. Considering the impact of offloading decision and resource allocation on computing offloading performance. In response to the above problems, a computing offloading resource allocation scheme using reinforcement learning in a MEC system is proposed,\n\n","x":1361,"y":4331,"width":527,"height":1077},
		{"id":"828f8d6eef86ddf6","type":"text","text":"### A DRL Agent for Jointly Optimizing Computation Offloading and Resource Allocation in MEC\n\nChen, Juan, Huanlai Xing, Zhiwen Xiao, Lexi Xu和Tao Tao. 《A DRL Agent for Jointly Optimizing Computation Offloading and Resource Allocation in MEC》. _IEEE Internet of Things Journal_ 8, 期 24 (2021年12月15日): 17508–24. [https://doi.org/10.1109/JIOT.2021.3081694](https://doi.org/10.1109/JIOT.2021.3081694).\n\n\nTraditional approaches, such as convex approximation [5], [6], game theory [7]–[9], and metaheuristics [4], [10], are not suitable for addressing dynamic JCORA problems in MEC. These methods usually suffer from exponentially increasing search space and heavy computational burdens, especially in large-scale scenarios. Adopting deep reinforcement learning (DRL) to handle JCORA problems has attracted increasingly more research interests because of the powerful deep neural networks (DNNs) [3], [12]–[20]. Deep deterministic policy gradient (DDPG) [16], [18] shows excellent potential when coping with dynamic optimization problems with a continuous action space. More details can be found in Section II. \n\nIn the traditional DDPG, both the actor and critic networks are based on fully connected networks (FCNs). However, FCNs generally suffer from two drawbacks. One is the huge number of trainable parameters, which increases the difficulty for training and significantly consumes computing resources. The other is that FCNs only extract the global discriminative state and action policy features, ignoring the temporal variation of task sequences that may contain useful shapelets for function approximation. Moreover, experience transitions are uniformly sampled from the replay buffer. This approach treats all experiences equally, regardless of their significance. However, ignoring the importance of valuable experiences usually leads to poor stability and slow convergence during training. \n\nTo overcome the disadvantages above, this article proposes temporal attentional deterministic policy gradient (TADPG), an improved DDPG agent for tackling the decentralized JCORA problem in a dynamic MEC environment. Running a TADPG agent on each MD requires fewer control costs between this MD and its corresponding MEC server. It is thus more suitable for large-scale scenarios, compared with those centralized JCORA methods. Our main contributions are summarized as follows.\n\n","x":-2845,"y":3308,"width":527,"height":1351},
		{"id":"38d1769d3407d63b","type":"text","text":"\n- Considering the stringent delay requirements of some applications and huge latency on wireless and wired communications between a vehicle and the cloud computing server, offloading vehicles’ tasks to the cloud computing server is sometimes inapplicable [13]–[15].\n- Meanwhile, physically increasing the amount of onboard resources would result in a serious increase in the manufacturing cost of vehicles.\n- The MEC server, as an extension of the cloud computing server, shifts computing and caching capabilities close to user devices [16]–[19].\n- It allows vehicles to offload tasks to it via multiple wireless communication technologies.\n- By saving the time consumption on communications between the MEC and the cloud computing server, the sensitive delay requirement of an offloaded task can be satisfied.\n- However, the amount of computing/caching resources is generally preset in each MEC-mounted base station (BS) while the resource demand from vehicle users is time-varying, underused, or wasted resource issues remain in the vehicular scenarios supported by only MEC-mounted BSs, especially when there exists bursty traffic caused by some social activities or events.\n- Taking the flexibility advantage of UAVs, mounting MEC servers in UAVs can help to address the above issues by dispatching the MEC-mounted UAVs to assist the designated BSs [11], [20].\n- Related applications have been also considered in different projects launched by many leading companies [21].\n\n- To implement MEC- and UAV-assisted vehicular networks, recent efforts have been made, with a focus on the deployment of MEC-mounted UAVs.\n- [22] has studied how to deploy and schedule the MEC-mounted UAVs to support vehicular applications.\n- Resource management is another research emphasis, with most works adopting optimization and reinforcement learning (RL) methods.\n- In [12], the transmit powers of vehicles and the trajectories of UAVs are jointly optimized to maximize the resource efficiency on MEC-mounted UAVs.\n- [23] proposes a deep RL-based adaptive computation offloading method to balance the tradeoff between energy consumption and data transmission delay in an MEC-based vehicular network.\n- [24] introduces a framework using MEC-mounted UAVs to support mobile users in the extended 5G network, with an RL method adopted to manage the resources carried by the UAV.\n- [25] proposes deep deterministic policy gradient (DDPG)- and hierarchical DDPG (HDDPG)-based schemes to jointly manage spectrum, computing, and caching resources available to an MEC-mounted BS.\n- However, most existing works have studied vehicular networks supported either by MEC-mounted BSs or UAVs.\n- There is still a need for efforts in efficiently allocating resources to support applications with various resource demands and heterogeneous quality-of-service (QoS) requirements in vehicular networks with MEC-mounted BSs and UAVs.\n\n\n- In this paper, the focus is on investigating multi-dimensional resource management in MEC- and UAV-assisted vehicular networks.\n- MEC servers are mounted at a macro eNodeB (MeNB) and in some UAVs to provide resource access to vehicles with limited onboard resources.\n- RL methods are adopted, inspired by existing works [23]–[26], to achieve real-time resource management in the considered scenario.\n- Due to sensitive delay requirements in certain vehicular applications (e.g., autonomous driving) and the wireless transmission time between a UAV and a controller, installing a central controller at the MeNB or an edge node for centralized resource management is sometimes infeasible.\n- To address this, a distributed cooperative scheme is developed based on a multi-agent RL method to manage the multi-dimensional resources available to the MEC-mounted MeNB and UAVs.\n- The main contributions of this work are summarized as follows:\n\n\n- In this paper, the focus is on investigating multi-dimensional resource management in MEC- and UAV-assisted vehicular networks.\n- MEC servers are mounted at a macro eNodeB (MeNB) and in some UAVs to provide resource access to vehicles with limited onboard resources.\n- RL methods are adopted, inspired by existing works [23]–[26], to achieve real-time resource management in the considered scenario.\n- Due to sensitive delay requirements in certain vehicular applications (e.g., autonomous driving) and the wireless transmission time between a UAV and a controller, installing a central controller at the MeNB or an edge node for centralized resource management is sometimes infeasible.\n- To address this, a distributed cooperative scheme is developed based on a multi-agent RL method to manage the multi-dimensional resources available to the MEC-mounted MeNB and UAVs.\n- The main contributions of this work are summarized as follows:\n1. To support as many offloaded tasks as possible while satisfying their QoS requirements, we formulate an individual optimization problem to each MEC server to jointly manage the MEC-mounted MeNB’s and UAVs’ spectrum, computing, and caching resources;\n2. Because of the vehicle association pattern variables, the formulated problems are coupled with each other and non-convex. To rapidly solve these problems to satisfy the sensitive delay requirements of the offloaded tasks, we transform each formulated problem according to the main idea of RL;\n3. We convert the transformed problems as a multi-agent problem by letting each MEC server act as an agent and develop a multi-agent DDPG (MADDPG) algorithm to solve it. Through training the MADDPG model offline, the vehicle association and resource allocation decisions can be made in real time by each MEC server.\n\n","x":-2286,"y":-212,"width":495,"height":3278,"color":"6"},
		{"id":"838ff88d8ddde355","type":"text","text":"- **Challenges in Vehicular Networks and Introduction of MEC Servers:**\n  - Considering the stringent delay requirements of some applications and huge latency on wireless and wired communications between a vehicle and the cloud computing server, offloading vehicles’ tasks to the cloud computing server is sometimes inapplicable [13]–[15].\n  - Meanwhile, physically increasing the amount of onboard resources would result in a serious increase in the manufacturing cost of vehicles.\n  - The MEC server, as an extension of the cloud computing server, shifts computing and caching capabilities close to user devices [16]–[19].\n  - It allows vehicles to offload tasks to it via multiple wireless communication technologies.\n  - By saving the time consumption on communications between the MEC and the cloud computing server, the sensitive delay requirement of an offloaded task can be satisfied.\n  - However, the amount of computing/caching resources is generally preset in each MEC-mounted base station (BS) while the resource demand from vehicle users is time-varying, underused, or wasted resource issues remain in the vehicular scenarios supported by only MEC-mounted BSs, especially when there exists bursty traffic caused by some social activities or events.\n  - Taking the flexibility advantage of UAVs, mounting MEC servers in UAVs can help to address the above issues by dispatching the MEC-mounted UAVs to assist the designated BSs [11], [20].\n  - Related applications have been also considered in different projects launched by many leading companies [21].\n\n- **Recent Efforts and Resource Management in MEC- and UAV-assisted Vehicular Networks:**\n  - To implement MEC- and UAV-assisted vehicular networks, recent efforts have been made, with a focus on the deployment of MEC-mounted UAVs.\n    - [22] has studied how to deploy and schedule the MEC-mounted UAVs to support vehicular applications.\n    - Resource management is another research emphasis, with most works adopting optimization and reinforcement learning (RL) methods.\n    - In [12], the transmit powers of vehicles and the trajectories of UAVs are jointly optimized to maximize the resource efficiency on MEC-mounted UAVs.\n    - [23] proposes a deep RL-based adaptive computation offloading method to balance the tradeoff between energy consumption and data transmission delay in an MEC-based vehicular network.\n    - [24] introduces a framework using MEC-mounted UAVs to support mobile users in the extended 5G network, with an RL method adopted to manage the resources carried by the UAV.\n    - [25] proposes deep deterministic policy gradient (DDPG)- and hierarchical DDPG (HDDPG)-based schemes to jointly manage spectrum, computing, and caching resources available to an MEC-mounted BS.\n    - However, most existing works have studied vehicular networks supported either by MEC-mounted BSs or UAVs.\n    - There is still a need for efforts in efficiently allocating resources to support applications with various resource demands and heterogeneous quality-of-service (QoS) requirements in vehicular networks with MEC-mounted BSs and UAVs.\n\n- **Focus and Contributions of the Paper:**\n  - In this paper, the focus is on investigating multi-dimensional resource management in MEC- and UAV-assisted vehicular networks.\n  - MEC servers are mounted at a macro eNodeB (MeNB) and in some UAVs to provide resource access to vehicles with limited onboard resources.\n  - RL methods are adopted, inspired by existing works [23]–[26], to achieve real-time resource management in the considered scenario.\n  - Due to sensitive delay requirements in certain vehicular applications (e.g., autonomous driving) and the wireless transmission time between a UAV and a controller, installing a central controller at the MeNB or an edge node for centralized resource management is sometimes infeasible.\n  - To address this, a distributed cooperative scheme is developed based on a multi-agent RL method to manage the multi-dimensional resources available to the MEC-mounted MeNB and UAVs.\n  - The main contributions of this work are summarized as follows:\n    1. To support as many offloaded tasks as possible while satisfying their QoS requirements, we formulate an individual optimization problem to each MEC server to jointly manage the MEC-mounted MeNB’s and UAVs’ spectrum, computing, and caching resources;\n    2. Because of the vehicle association pattern variables, the formulated problems are coupled with each other and non-convex. To rapidly solve these problems to satisfy the sensitive delay requirements of the offloaded tasks, we transform each formulated problem according to the main idea of RL;\n    3. We convert the transformed problems as a multi-agent problem by letting each MEC server act as an agent and develop a multi-agent DDPG (MADDPG) algorithm to solve it. Through training the MADDPG model offline, the vehicle association and resource allocation decisions can be made in real time by each MEC server.","x":-1654,"y":156,"width":695,"height":2196,"color":"5"},
		{"id":"aba8b6138abd39c0","type":"text","text":"- **MEC-Based IoT Networks:**\n  - In MEC-based IoT networks, devices can offload computation tasks to the MEC server, improving task processing speed and saving device energy [15]–[17].\n  - The primary technical challenge is determining when, whether, and how many computation tasks should be offloaded.\n  - A significant body of literature focuses on designing optimal strategies under various performance requirements [18]–[21].\n  - For long-term energy efficiency in IoT networks, [18] proposes an efficient edge computing infrastructure.\n  - Addressing stochastic task arrivals, wireless channel variations, congested air interfaces, and prohibitive feedback, [19] generates asymptotically optimal schedules tolerant to out-of-date network knowledge, relieving stringent requirements on feedback.\n  - Optimal scheduling solutions and energy-efficient resource allocation policies for MEC are proposed in [20] and [21], respectively.\n\n- **Vehicular Edge Computing Networks:**\n  - Researchers extensively explore the structure and resource allocation methods in vehicular edge computing networks, given the significant role of vehicles as User Equipment (UE) in IoT systems [22]–[27].\n  - C. Wang et al. propose a scalable SDN-enabled MEC architecture integrating a heterogeneous vehicular network to decrease overall delay and offload traffic load from the backbone network [22].\n  - To address latency and transmission cost of computation offloading, a cloud-based MEC offloading framework is proposed for vehicular networks in [23].\n  - In [24], a target server selection policy is presented, based on the MEC-assisted vehicular offloading mode, aiming to improve task offloading reliability in the case of vehicular data transmission failure.\n  - Novel MEC-based vehicular networks are proposed in [25], [26], where computation offloading policies are carefully designed for different scenarios.\n  - Reinforcement learning is employed for long-term resource provision in vehicular clouds, addressing dynamic demands for resources and stringent Quality of Service (QoS) requirements [27].\n  - However, in existing literature, vehicles predominantly serve as users in the MEC network, where edge servers are statically deployed and may lead to \"service holes\" due to an explosion of service requests from a tremendous number of User Equipments (UEs).\n\n- **Introduction to Vehicle Edge Computing (VEC) Network:**\n  - The paper focuses on designing a Vehicle Edge Computing (VEC) network, empowering vehicles to provide computation services alongside traditional edge servers.\n  - Traditional edge servers, connected to road-side units, small-cell base stations, etc., have fixed locations, and the proposed architecture aims to extend computation service range, enhancing the flexibility of the Mobile Edge Computing (MEC) network.\n\n- **Efficient Computation Offloading Scheme and Optimization Problem:**\n  - The paper proposes an efficient computation offloading scheme for User Equipments (UEs), considering the delay of computation tasks generated by UEs.\n  - An optimization problem is formulated to maximize the total utility of the proposed VEC network.\n\n- **Addressing Stochastic Traffic and Communication Uncertainty:**\n  - The stochastic traffic and communication uncertainty in the vehicular communication environment are crucial challenges to be addressed.\n  - The Q-learning method, a model-free reinforcement learning approach, is chosen due to its suitability for solving problems in the vehicle edge computing network where environment elements are not known [32].\n  - The paper introduces deep reinforcement learning (DRL), which uses deep neural networks to approximate the Q-function, providing greater performance and more robust learning [33]–[36].\n  - The proposed problem is further formulated as a semi-Markov process, and two reinforcement learning methods (Q-learning and DRL) are proposed to determine the policies of computation offloading and resource allocation.\n\n- **Main Contributions:**\n  1. The proposal of a vehicle edge computing network architecture where vehicles can provide computation services for UEs, enhancing the flexibility and scalability of the MEC-based IoT system.\n  2. Introduction of an efficient offloading scheme for the vehicle edge computing network, considering both delay and limited computation capabilities of vehicles and edge servers. Formulation of an optimization problem to maximize the total utility of the network.\n  3. Addressing stochastic traffic and uncertain communication conditions by reformulating the problem as a semi-Markov process. Proposing Q-learning-based reinforcement learning and DRL methods to determine policies for computation offloading and resource allocation.","x":450,"y":562,"width":710,"height":2082,"color":"5"}
	],
	"edges":[
		{"id":"11bd23db47de2651","fromNode":"60cf73ff2492e3e8","fromSide":"right","toNode":"38d1769d3407d63b","toSide":"left"},
		{"id":"17c31e7664079810","fromNode":"38d1769d3407d63b","fromSide":"right","toNode":"838ff88d8ddde355","toSide":"left"},
		{"id":"8f1e0a889fd9123c","fromNode":"4377f960d6d505c5","fromSide":"right","toNode":"c542af179514c130","toSide":"left"},
		{"id":"8f17088ec94f94ee","fromNode":"4377f960d6d505c5","fromSide":"right","toNode":"756c3e54b6e06e7e","toSide":"left"},
		{"id":"efcdfdfcde5eb97e","fromNode":"c542af179514c130","fromSide":"right","toNode":"c58793506f600720","toSide":"left"},
		{"id":"dcf4bd84090c21b3","fromNode":"59e271b6d698153c","fromSide":"right","toNode":"48d95710b6d6f974","toSide":"left"},
		{"id":"ac695e35c682a4f8","fromNode":"48d95710b6d6f974","fromSide":"right","toNode":"df604f2483501e93","toSide":"left"},
		{"id":"ba0e2ea313d5dd6c","fromNode":"e283e054643c750e","fromSide":"right","toNode":"5d6cf91d30077f64","toSide":"left"},
		{"id":"1b7a3500e29351d5","fromNode":"5d6cf91d30077f64","fromSide":"right","toNode":"23fd185fed78b759","toSide":"left"},
		{"id":"817921b15b77dc0a","fromNode":"8a7016c5db0d8166","fromSide":"right","toNode":"286bdbd3744bbcd2","toSide":"left"},
		{"id":"e684eb63af253ab4","fromNode":"8a7016c5db0d8166","fromSide":"right","toNode":"1dab1d1b7467470a","toSide":"left"},
		{"id":"bb18e380bd468a16","fromNode":"286bdbd3744bbcd2","fromSide":"right","toNode":"7c8ebbea53acbd4d","toSide":"left"},
		{"id":"6ca368bb9136b4b0","fromNode":"5911a2a71cba17fe","fromSide":"right","toNode":"aba8b6138abd39c0","toSide":"left"},
		{"id":"0434c3c989e978a7","fromNode":"bdc8ca778f55da5e","fromSide":"right","toNode":"bb560557ff125046","toSide":"left"},
		{"id":"0eca2135ace93300","fromNode":"bdc8ca778f55da5e","fromSide":"right","toNode":"405938e52d4d732c","toSide":"left"},
		{"id":"97d20b55b47d6372","fromNode":"bb560557ff125046","fromSide":"right","toNode":"462aeef697230fbf","toSide":"left"},
		{"id":"d8cd93a6a876c228","fromNode":"ec67400a03415c26","fromSide":"right","toNode":"126967b0e284f732","toSide":"left"},
		{"id":"a92b10a8ba783810","fromNode":"126967b0e284f732","fromSide":"right","toNode":"1ebaf5ca1336fdd6","toSide":"left"},
		{"id":"fc5087a9394a456f","fromNode":"93ea1152bc6b1264","fromSide":"right","toNode":"f22230870406c474","toSide":"left"},
		{"id":"d71a7318860f648f","fromNode":"f22230870406c474","fromSide":"right","toNode":"b9441fbc2f7662a2","toSide":"left"},
		{"id":"2a4be0317fd9d781","fromNode":"828f8d6eef86ddf6","fromSide":"right","toNode":"1d1686ac908b30bd","toSide":"left"},
		{"id":"c94f84b9f8064d23","fromNode":"1d1686ac908b30bd","fromSide":"right","toNode":"d1e05b13e7f28935","toSide":"left"}
	]
}