{
	"nodes":[
		{"id":"50935e0801421240","type":"text","text":"### A Collaborative Scheduling Strategy for IoV Computing Resources Considering Location Privacy Protection in Mobile Edge Computing Environment\n\n![[Pasted image 20231219105051.png]]\nFig. 1 System model of multi-area multi MEC server\n\n\n![[Pasted image 20231219110607.png]]\nFig. 3 Analysis of vehicle edge computing\n\n![[Pasted image 20231219110631.png]]\nFig. 4 Interaction block diagram of reinforcement learning","x":-1079,"y":-338,"width":656,"height":1564},
		{"id":"eae7b585f932bf64","type":"text","text":"### A Computing Offloading Resource Allocation Scheme Using Deep Reinforcement Learning in Mobile Edge Computing Systems\n\n\n![[Pasted image 20231219111931.png]]\nFig. 1 The system model\n\n\n![[Pasted image 20231219111958.png]]\nFig. 2 The framework of reinforcement learning","x":-1079,"y":1260,"width":656,"height":982},
		{"id":"1924a7737fb04f3e","type":"text","text":"### Deep Reinforcement Learning for Offloading and Resource Allocation in Vehicle Edge Computing and Networks\n\n\n![[Pasted image 20231219142802.png]]\nFig. 1. System model of vehicle-assisted MEC Network.\n","x":-371,"y":-338,"width":656,"height":576},
		{"id":"0e91348e03bc181d","type":"text","text":"### Deep Reinforcement Learning-Based Dynamic Resource Management for Mobile Edge Computing in Industrial Internet of Things\n\n\n![[Pasted image 20231219151419.png]]\nFig. 1. MEC-enabled industrial IoT network.","x":-371,"y":323,"width":656,"height":599},
		{"id":"4a9b65861e29b0a3","type":"text","text":"### DRL-Based Long-Term Resource Planning for Task Offloading Policies in Multiserver Edge Computing Networks\n\n\n![[Pasted image 20231219153006.png]]\nFig. 1. MEC Network Architecture.\n\n![[Pasted image 20231219153039.png]]\nFig. 2. Overall Solution of Task Offloading Management (P1: Optimization of long-term resource scheduling; P2: Joint optimization of offloading decision and resources allocation).\n\n![[Pasted image 20231219153105.png]]\nFig. 3. DQN Centralized Training and Centralized Execution Architecture.\n\n![[Pasted image 20231219153123.png]]\nFig. 4. The Structure of DRL Multi-Agent Actor-Critic.\n\n![[Pasted image 20231219153145.png]]\nFig. 5. MADDPG Centralized Training and Distributed Execution Architecture.","x":371,"y":-325,"width":656,"height":2208},
		{"id":"d3e3db331d7ba232","type":"text","text":"### Dependency-Aware Task Scheduling in Vehicular Edge Computing\n\n\n![[Pasted image 20231219151523.png]]\nFig. 1. Architecture of VEC.","x":-1079,"y":2260,"width":656,"height":505},
		{"id":"6f91ce939716358e","type":"text","text":"### A DRL Agent for Jointly Optimizing Computation Offloading and Resource Allocation in MEC\n\n\n![[Pasted image 20231219112340.png]]\nFig. 1. Example MEC system.\n\n![[Pasted image 20231219112416.png]]\nFig. 2. Structure of the TADPG agent.\n\n![[Pasted image 20231219112439.png]]\nFig. 3. Structure of TFEN.","x":-371,"y":979,"width":656,"height":1404},
		{"id":"0455839189ffe56e","type":"text","text":"### A Truthful Reverse-Auction Mechanism for Computation Offloading in Cloud-Enabled Vehicular Network\n\n\n![[Pasted image 20231219115009.png]]\nFig. 1. Multibuyerâ€“multiseller cloud-enabled vehicular network framework.\n","x":371,"y":1950,"width":656,"height":719},
		{"id":"ea3e24111581cd83","type":"text","text":"### Deep Reinforcement Learning Based Resource Management for Multi-Access Edge Computing in Vehicular Networks\n\n\n![[Pasted image 20231219141736.png]]\nFig. 1. An illustration of MEC-based vehicular network model.\n\n![[Pasted image 20231219141846.png]]\nFig. 2. Dynamic spectrum management frameworks.\n\n![[Pasted image 20231219141920.png]]\nFig. 3. The fundamental deep RL architecture in the MEC-based vehicular Network.\n\n![[Pasted image 20231219141942.png]]\nFig. 4. The architecture of the DDPG learning.","x":1088,"y":-325,"width":656,"height":1661},
		{"id":"e76abbeff00d1544","type":"text","text":"### Efficient Task Scheduling for Servers with Dynamic States in Vehicular Edge Computing\n\n\n![[Pasted image 20231219154046.png]]\nFig. 1. The architecture of vehicular edge computing.","x":1088,"y":1400,"width":656,"height":564},
		{"id":"76fa821d9451ca57","type":"text","text":"### Multi-Agent Reinforcement Learning Based Resource Management in MEC- and UAV-Assisted Vehicular Networks\n\n\n![[Pasted image 20231219154714.png]]\nFig. 1. An illustration of the MEC- and UAV-assisted vehicular network.\n\n![[Pasted image 20231219154745.png]]\nFig. 2. A simplified MEC- and UAV-assisted vehicular network scenario for multi-dimensional resource management.\n\n![[Pasted image 20231219154818.png]]\nFig. 3. The MADDPG framework in the MEC- and UAV-assisted vehicular network.\n","x":1807,"y":-314,"width":656,"height":1295},
		{"id":"181837557befbc02","type":"text","text":"### Reverse Auction-Based Computation Offloading and Resource Allocation in Mobile Cloud-Edge Computing\n\n\n![[Pasted image 20231230134740.png]]\nFig. 1. System Architecture of Mobile Cloud-Edge Computation Offloading.","x":1088,"y":2032,"width":656,"height":635},
		{"id":"fecff4911c69f4cd","type":"text","text":"### A Deep Reinforcement Learning Approach to Resource Management in Hybrid Clouds Harnessing Renewable Energy and Task Scheduling\n\n\n![[Pasted image 20231219112144.png]]\nFig. 2. System Architecture\n\n![[Pasted image 20231219112111.png]]\nFig. 3. Concept Diagram of DRL","x":1807,"y":1007,"width":656,"height":975}
	],
	"edges":[]
}