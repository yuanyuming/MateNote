{
	"nodes":[
		{"id":"50935e0801421240","x":-223,"y":-390,"width":656,"height":1328,"type":"text","text":"### A Collaborative Scheduling Strategy for IoV Computing Resources Considering Location Privacy Protection in Mobile Edge Computing Environment\n\n![[Pasted image 20231219105051.png]]\nFig. 1 System model of multi-area multi MEC server\n\n\n![[Pasted image 20231219110607.png]]\nFig. 3 Analysis of vehicle edge computing\n\n![[Pasted image 20231219110631.png]]\nFig. 4 Interaction block diagram of reinforcement learning"},
		{"id":"eae7b585f932bf64","x":-223,"y":983,"width":656,"height":822,"type":"text","text":"### A Computing Offloading Resource Allocation Scheme Using Deep Reinforcement Learning in Mobile Edge Computing Systems\n\n\n![[Pasted image 20231219111931.png]]\nFig. 1 The system model\n\n\n![[Pasted image 20231219111958.png]]\nFig. 2 The framework of reinforcement learning"},
		{"id":"6f91ce939716358e","x":-223,"y":1876,"width":656,"height":1404,"type":"text","text":"### A DRL Agent for Jointly Optimizing Computation Offloading and Resource Allocation in MEC\n\n\n![[Pasted image 20231219112340.png]]\nFig. 1. Example MEC system.\n\n![[Pasted image 20231219112416.png]]\nFig. 2. Structure of the TADPG agent.\n\n![[Pasted image 20231219112439.png]]\nFig. 3. Structure of TFEN."},
		{"id":"0455839189ffe56e","x":-223,"y":3336,"width":656,"height":719,"type":"text","text":"### A Truthful Reverse-Auction Mechanism for Computation Offloading in Cloud-Enabled Vehicular Network\n\n\n![[Pasted image 20231219115009.png]]\nFig. 1. Multibuyerâ€“multiseller cloud-enabled vehicular network framework.\n"},
		{"id":"ea3e24111581cd83","x":-223,"y":4093,"width":656,"height":1391,"type":"text","text":"### Deep Reinforcement Learning Based Resource Management for Multi-Access Edge Computing in Vehicular Networks\n\n\n![[Pasted image 20231219141736.png]]\nFig. 1. An illustration of MEC-based vehicular network model.\n\n![[Pasted image 20231219141846.png]]\nFig. 2. Dynamic spectrum management frameworks.\n\n![[Pasted image 20231219141920.png]]\nFig. 3. The fundamental deep RL architecture in the MEC-based vehicular Network.\n\n![[Pasted image 20231219141942.png]]\nFig. 4. The architecture of the DDPG learning."},
		{"id":"1924a7737fb04f3e","x":490,"y":-390,"width":656,"height":436,"type":"text","text":"### Deep Reinforcement Learning for Offloading and Resource Allocation in Vehicle Edge Computing and Networks\n\n\n![[Pasted image 20231219142802.png]]\nFig. 1. System model of vehicle-assisted MEC Network.\n"},
		{"id":"0e91348e03bc181d","x":490,"y":94,"width":656,"height":458,"type":"text","text":"### Deep Reinforcement Learning-Based Dynamic Resource Management for Mobile Edge Computing in Industrial Internet of Things\n\n\n![[Pasted image 20231219151419.png]]\nFig. 1. MEC-enabled industrial IoT network."},
		{"id":"d3e3db331d7ba232","x":490,"y":610,"width":656,"height":423,"type":"text","text":"### Dependency-Aware Task Scheduling in Vehicular Edge Computing\n\n\n![[Pasted image 20231219151523.png]]\nFig. 1. Architecture of VEC."},
		{"id":"4a9b65861e29b0a3","x":490,"y":1070,"width":656,"height":1895,"type":"text","text":"### DRL-Based Long-Term Resource Planning for Task Offloading Policies in Multiserver Edge Computing Networks\n\n\n![[Pasted image 20231219153006.png]]\nFig. 1. MEC Network Architecture.\n\n![[Pasted image 20231219153039.png]]\nFig. 2. Overall Solution of Task Offloading Management (P1: Optimization of long-term resource scheduling; P2: Joint optimization of offloading decision and resources allocation).\n\n![[Pasted image 20231219153105.png]]\nFig. 3. DQN Centralized Training and Centralized Execution Architecture.\n\n![[Pasted image 20231219153123.png]]\nFig. 4. The Structure of DRL Multi-Agent Actor-Critic.\n\n![[Pasted image 20231219153145.png]]\nFig. 5. MADDPG Centralized Training and Distributed Execution Architecture."},
		{"id":"e76abbeff00d1544","x":490,"y":3004,"width":656,"height":466,"type":"text","text":"### Efficient Task Scheduling for Servers with Dynamic States in Vehicular Edge Computing\n\n\n![[Pasted image 20231219154046.png]]\nFig. 1. The architecture of vehicular edge computing."},
		{"id":"76fa821d9451ca57","x":490,"y":3505,"width":656,"height":1104,"type":"text","text":"### Multi-Agent Reinforcement Learning Based Resource Management in MEC- and UAV-Assisted Vehicular Networks\n\n\n![[Pasted image 20231219154714.png]]\nFig. 1. An illustration of the MEC- and UAV-assisted vehicular network.\n\n![[Pasted image 20231219154745.png]]\nFig. 2. A simplified MEC- and UAV-assisted vehicular network scenario for multi-dimensional resource management.\n\n![[Pasted image 20231219154818.png]]\nFig. 3. The MADDPG framework in the MEC- and UAV-assisted vehicular network.\n"},
		{"id":"181837557befbc02","x":490,"y":4643,"width":656,"height":554,"type":"text","text":"### Reverse Auction-Based Computation Offloading and Resource Allocation in Mobile Cloud-Edge Computing\n\n\n![[Pasted image 20231230134740.png]]\nFig. 1. System Architecture of Mobile Cloud-Edge Computation Offloading."},
		{"id":"fecff4911c69f4cd","x":490,"y":5249,"width":656,"height":787,"type":"text","text":"### A Deep Reinforcement Learning Approach to Resource Management in Hybrid Clouds Harnessing Renewable Energy and Task Scheduling\n\n\n![[Pasted image 20231219112144.png]]\nFig. 2. System Architecture\n\n![[Pasted image 20231219112111.png]]\nFig. 3. Concept Diagram of DRL"}
	],
	"edges":[]
}