---
date created: 2023-12-04 10:01
date updated: 2023-12-04 15:39
---

---

- 引言
  - [x] 介绍车联网的背景和应用场景
  - [x] 分析车联网中的任务调度问题和挑战
  - [x] 概述基于多智能体强化学习和反向拍卖机制的解决方案
  - [x] 阐述论文的主要贡献和创新点。

---

## 1. 引言

近年来，随着物联网（IoT）技术和信息通信技术（ICT）的快速发展，现代汽车正迎来一场科技革命。无线嵌入式传感设备和与5G相关的技术的引入，使得智能交通系统（ITS）成为现实，并成为智能城市不可或缺的组成部分。在这个背景下，车联网（IoV）作为ITS的重要组成部分，通过车辆间、车辆与基础设施之间的信息交换和协同服务，为驾驶员提供先前的交通流信息，从而提高道路安全性、交通效率和驾驶体验。本文主要关注车联网中的任务卸载问题，即如何将车辆的计算密集型任务迁移到边缘服务器上执行，以提高车辆的性能和用户的体验。

车联网（Vehicular Ad Hoc Networks, VANETs）构成了一个由移动车辆和固定基础设施组成的自组织网络，旨在为车辆提供智能、安全和高效的服务。随着车辆技术的进步，如自动驾驶、视频分析和个人助手等应用的普及，车辆可以执行越来越多计算密集型和数据密集型的任务，包括但不限于导航、视频流传输以及车载娱乐等。然而，随着任务需求的增加，车辆的计算能力和电池容量逐渐变得有限，难以满足复杂或对延迟敏感的任务需求。为解决这一问题，移动边缘计算（MEC）作为一种新的计算范式应运而生。通过在道路边缘部署多个MEC服务器，它为车辆提供低延迟、高带宽的计算资源和服务。这项技术使车辆能够将部分或全部任务卸载到MEC服务器上执行，从而降低了自身的能耗和时间开销，为车联网系统带来更安全、更高效和更智能的驾驶体验。

车联网（Vehicular Ad Hoc Networks, VANETs）构成了一个由移动车辆和固定基础设施组成的自组织网络，旨在为车辆提供智能、安全和高效的服务。在车联网（IoV）领域，任务调度则显得尤为重要且具有挑战性。其核心目标在于通过巧妙地将计算密集型服务分配给车载单元（OBU）或边缘服务器，以提高车辆性能和用户体验。IoV中的计算任务范围广泛，涵盖语音识别、自然语言处理、计算机视觉、机器学习、增强现实等多个方面。这些任务因其类型、大小、优先级、延迟、能耗等特征和需求而各异。然而，随着任务需求的增加，车辆的计算能力和电池容量逐渐变得有限，难以满足复杂或对延迟敏感的任务需求。为解决这一问题，移动边缘计算（MEC）作为一种新的计算范式应运而生。通过在道路边缘部署多个MEC服务器，它为车辆提供低延迟、高带宽的计算资源和服务。这项技术使车辆能够将部分或全部任务卸载到MEC服务器上执行，从而降低了自身的能耗和时间开销，为车联网系统带来更安全、更高效和更智能的驾驶体验。任务调度的挑战主要源自对任务属性、实时状态以及车辆和边缘服务器状态的多方面考量。然而，在移动边缘计算（MEC）环境下，有效地进行任务卸载和调度涉及多重挑战。这包括基于任务特性和实时状态做出任务卸载决策、在不同MEC服务器之间平衡负载以最大化系统效用并确保服务质量（QoS）。

为了解决车联网中的任务调度问题，本文提出了一种创新的方法，结合了多智能体强化学习和逆向拍卖机制。该方法旨在通过动态分配计算密集型任务的执行计划，根据任务、车辆和边缘服务器之间的资源匹配程度，并通过激励机制促使车辆和边缘服务器之间的合作，以提高任务调度的效率和性能，降低总成本。

具体而言，本文采用了多智能体强化学习算法，使车辆能够根据本地和全局信息自主学习和更新其任务调度策略。通过该算法，车辆可以更智能地决策是在本地执行任务还是卸载到边缘服务器上，从而充分利用系统资源，提高执行效果。同时，引入了逆向拍卖机制，通过资源分配和价格协商，实现了车辆和边缘服务器之间的有效合作。这一机制旨在平衡竞争与合作，提高系统效率和公平性，确保资源的合理分配。

在这个背景下，深度强化学习（DRL）成为了关键的技术手段，尤其是在面对高维状态和动作空间的问题时。DRL基于神经网络和马尔可夫决策过程（MDP）模型，使得智能体能够与环境交互，通过最大化长期奖励来学习最优策略。在多智能体环境下，引入了多智能体强化学习（MARL）问题，其采用不同方法评估和生成策略，包括基于价值、基于策略和演员-评论者类型。MARL方法以其适应性、鲁棒性、可扩展性和分布性等优势，在复杂、动态和不确定的环境中取得了广泛应用，提高系统的效率和稳定性。

在拍卖机制方面，本文采用了逆拍卖机制，该机制在车联网中的应用场景丰富多样，包括资源或服务交易，如频谱、缓存、计算和数据等。在车联网中，逆拍卖机制不仅能够激励车辆用户共享资源或执行任务，还可应用于社会福利任务的分配，如交通管理、环境监测、数据收集等。通过逆拍卖，平台能够寻找愿意以最低价格提供服务或执行任务的车辆用户或服务器，并与其签署标准合同，从而实现成本节省。

本文旨在使用多智能体深度强化学习（MADRL）训练每个MEC服务器上的策略网络，使其能够智能计算接受任务的长期奖励，并根据最大化奖励的原则向用户出价。通过结合深度强化学习和逆向拍卖机制，本文设计了一种全面的车联网任务调度方法，旨在提高效率、性能和公平性，降低总成本。

本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文的主要贡献如下：

- 将反向拍卖应用于车联网中的任务卸载问题，实现了分布式、自适应、激励兼容的任务调度。
- 设计了一个基于 PPO+LSTM 的报价策略，利用 LSTM 的记忆能力，捕捉任务卸载的时序特征和长期依赖，提高报价策略的性能和效果。
- 开发了一个基于 Python 的开源仿真环境 —— VehicleJobScheduling，模拟了车辆任务卸载的过程，并提供了一些常用的评估指标。
- 通过仿真实验，验证了本文方法的有效性和优越性，以及强化学习和反向拍卖机制的优势和适用性，并与其他基准方法进行了对比分析。

本文的结构安排如下：第二节综述了相关工作，第三节阐述了问题的建模，第四节描述了方法的设计，第五节展示了仿真环境和实验结果，第六节总结了本文的主要结论和未来工作。
