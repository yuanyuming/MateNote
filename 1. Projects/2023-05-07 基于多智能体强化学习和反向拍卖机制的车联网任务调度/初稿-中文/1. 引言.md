---
date created: 2023-12-04 10:01
---

---

- 引言
  - [x] 介绍车联网的背景和应用场景
  - [x] 分析车联网中的任务调度问题和挑战
  - [x] 概述基于多智能体强化学习和反向拍卖机制的解决方案
  - [ ] 阐述论文的主要贡献和创新点。

---

## 1. 引言

近年来，随着物联网（IoT）技术和信息通信技术（ICT）的快速发展，现代汽车正迎来一场科技革命。无线嵌入式传感设备和与5G相关的技术的引入，使得智能交通系统（ITS）成为现实，并成为智能城市不可或缺的组成部分。在这个背景下，车联网（IoV）作为ITS的重要组成部分，通过车辆间、车辆与基础设施之间的信息交换和协同服务，为驾驶员提供先前的交通流信息，从而提高道路安全性、交通效率和驾驶体验。

然而，随着车辆技术的进步，如自动驾驶、视频分析和个人助手等应用的普及，车辆的计算能力和电池容量逐渐变得有限，难以满足复杂或对延迟敏感的任务需求。为解决这一问题，移动边缘计算（MEC）作为一种新的计算范式应运而生。通过在道路边缘部署多个MEC服务器，它为车辆提供低延迟、高带宽的计算资源和服务。这项技术使车辆能够将部分或全部任务卸载到MEC服务器上执行，从而降低了自身的能耗和时间开销，为车联网系统带来更安全、更高效和更智能的驾驶体验。

车联网（Vehicular Ad Hoc Networks, VANETs）构成了一个由移动车辆和固定基础设施组成的自组织网络，旨在为车辆提供智能、安全和高效的服务。随着车辆计算能力和通信带宽的不断提升，车辆可以执行越来越多计算密集型和数据密集型的任务，包括但不限于导航、视频流传输以及车载娱乐等。然而，由于车辆自身资源的有限性和动态性，以及车联网环境的复杂性和不确定性，车辆通常难以满足这些任务对资源的高需求。在这一背景下，任务卸载（Task Offloading）崭露头角，作为一种有效的解决方案，它能够将车辆任务迁移到更强大和稳定的边缘服务器上执行，从而节省车辆资源、降低执行延迟，提升任务执行效果。

在车联网（IoV）领域，任务调度则显得尤为重要且具有挑战性。其核心目标在于通过巧妙地将计算密集型服务分配给车载单元（OBU）或边缘服务器，以提高车辆性能和用户体验。IoV中的计算任务范围广泛，涵盖语音识别、自然语言处理、计算机视觉、机器学习、增强现实等多个方面。这些任务因其类型、大小、优先级、延迟、能耗等特征和需求而各异。

任务调度的挑战主要源自对任务属性、实时状态以及车辆和边缘服务器状态的多方面考量。其中包括车辆的位置、速度，以及服务器的资源和效用等因素。在决策过程中，需要准确判断是在车辆本地执行任务还是将其卸载到边缘服务器上。然而，在移动边缘计算（MEC）环境下，有效地进行任务卸载和调度涉及多重挑战。这包括基于任务特性和实时状态做出任务卸载决策、在不同MEC服务器之间平衡负载以最大化系统效用并确保服务质量（QoS），以及设计激励机制以促使服务器之间的合作，防止自私或恶意行为的发生。

为了解决车联网中的任务调度问题，本文提出了一种创新的方法，结合了多智能体强化学习和逆向拍卖机制。该方法旨在通过动态分配计算密集型任务的执行计划，根据任务、车辆和边缘服务器之间的资源匹配程度，并通过激励机制促使车辆和边缘服务器之间的合作，以提高任务调度的效率和性能，降低总成本。

具体而言，本文采用了多智能体强化学习算法，使车辆能够根据本地和全局信息自主学习和更新其任务调度策略。通过该算法，车辆可以更智能地决策是在本地执行任务还是卸载到边缘服务器上，从而充分利用系统资源，提高执行效果。同时，引入了逆向拍卖机制，通过资源分配和价格协商，实现了车辆和边缘服务器之间的有效合作。这一机制旨在平衡竞争与合作，提高系统效率和公平性，确保资源的合理分配。

在这个背景下，深度强化学习（DRL）成为了关键的技术手段，尤其是在面对高维状态和动作空间的问题时。DRL基于神经网络和马尔可夫决策过程（MDP）模型，使得智能体能够与环境交互，通过最大化长期奖励来学习最优策略。在多智能体环境下，引入了多智能体强化学习（MARL）问题，其采用不同方法评估和生成策略，包括基于价值、基于策略和演员-评论者类型。MARL方法以其适应性、鲁棒性、可扩展性和分布性等优势，在复杂、动态和不确定的环境中取得了广泛应用，提高系统的效率和稳定性。

在拍卖机制方面，本文采用了逆拍卖机制，该机制在车联网中的应用场景丰富多样，包括资源或服务交易，如频谱、缓存、计算和数据等。在车联网中，逆拍卖机制不仅能够激励车辆用户共享资源或执行任务，还可应用于社会福利任务的分配，如交通管理、环境监测、数据收集等。通过逆拍卖，平台能够寻找愿意以最低价格提供服务或执行任务的车辆用户或服务器，并与其签署标准合同，从而实现成本节省。

本文旨在使用多智能体深度强化学习（MADRL）训练每个MEC服务器上的策略网络，使其能够智能计算接受任务的长期奖励，并根据最大化奖励的原则向用户出价。通过结合深度强化学习和逆向拍卖机制，本文设计了一种全面的车联网任务调度方法，旨在提高效率、性能和公平性，降低总成本。

---


本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文的主要贡贡献和创新点如下：

- 本文首次将反向拍卖应用于车联网中的任务卸载问题，并设计了一个基于强化学习（Reinforcement Learning, RL） 的报价策略，使得服务器能够根据任务特征和资源源状况动态地调整报价。
- 本文通过理论分析和和仿真实验，验证了本文方法的正确性和优越性，以及对车联网性能的改善效果。
- 本文开发了一个基于 Python 的开源源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。

本文主要有以下几个方面：

- 完成了对车联网环境下边缘服务器任务卸载的建模
- 设计了一种基于反向拍卖机制的资源分配
- 建立了反向拍卖机制的车联网任务调度的强化学习环境
- 提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务调度方法，结合了机器学习和博弈论的优势，实现了分布式、自适应、激励兼容的任务调度。

本文的结构如下：第二节介绍了相关工作；第三节介绍了问题的建模和方法的原理；第四节介绍了仿真环境的设计和参数设置；第五节介绍了实验结果和分析；第六节总结了本文的结论和展望。

---

## 摘要

车联网是一种将车辆与互联网相连的技术，它可以提供各种智能化的服务，如导航、娱乐、安全等。然而，车辆的计算能力和能源有限，无法满足复杂和耗时的任务的需求。为了解决这个问题，车辆可以将部分任务卸载到边缘服务器上，从而节省能耗和提高性能。然而，任务卸载的过程涉及到多个车辆和多个服务器之间的协作和竞争，如何有效地分配任务和资源，是一个具有挑战性的问题。本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文还开发了一个基于 Python 的开源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。本文通过在该环境中进行一系列的仿真实验，验证了本文方法的有效性和优越性。

车联网是一种利用车辆之间和车辆与基础设施之间的无线通信技术，实现智能交通系统的网络技术。车联网具有广泛的应用场景，例如标准化、高效的交通管理、道路安全和信息娱乐等。随着车辆搭载的通信系统、计算设备、存储空间和传感器的增加，车联网也面临着更多的挑战和需求。

在车联网中，一个重要的问题是如何有效地调度车辆的计算任务，以提高车辆的性能和用户的体验。随着5G通信技术和边缘计算技术的发展，车联网中出现了大量的计算密集型服务，例如语音识别、自然语言处理、计算机视觉、机器学习、增强现实等。这些服务需要大量的计算资源来执行，而车辆上搭载的OBU（车载单元）由于重量、尺寸和电池寿命等因素，往往缺乏足够的计算资源。因此，如何有效地调度车联网中的任务，使得它们能够在满足时效性和能耗等约束条件下，在车辆或边缘服务器上完成，是一个重要而具有挑战性的问题。计算任务调度是指根据任务的特征和需求，决定将任务在车辆本地执行还是卸载到边缘服务器或云端执行。计算任务调度涉及到多个方面的因素，例如任务的类型、大小、优先级、延迟、能耗等，以及车辆的位置、速度、方向、资源、效用等2。因此，计算任务调度是一个复杂的优化问题，需要考虑多个目标和约束条件。

1. <https://arxiv.org/ftp/arxiv/papers/2101/2101.04539.pdf>
2. <https://www.sciencedirect.com/science/article/abs/pii/S1084804513001793>

为了解决这个问题，本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务调度方法。该方法利用多智能体强化学习算法，使得车辆可以根据局部和全局的信息，自主地学习和更新自己的任务调度策略。同时，该方法利用反向拍卖机制，实现了车辆和边缘服务器之间的资源分配和价格协商。该方法可以有效地平衡车辆与边缘服务器之间的竞争和合作，提高系统的效率和公平性。本文旨在提出一种基于多智能体强化学习和反向拍卖机制的车联网任务调度方法，该方法可以动态地根据任务、车辆和边缘服务器之间的资源匹配程度，为每个任务分配一个合适的执行方案，并通过激励机制保证车辆和边缘服务器之间的合作和公平。本文认为，这种方法可以有效地提高任务调度的效率和性能，并降低任务执行过程中产生的总成本。

本文的主要贡献和创新点有以下几个方面：
• 提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务调度方法，结合了机器学习和博弈论的优势，实现了分布式、自适应、激励兼容的任务调度。
• 设计了一种基于深度神经网络的多智能体强化学习算法，利用历史数据和实时反馈，有效地解决了高维状态空间和延迟奖励信号的问题。
• 设计了一种基于反向拍卖机制的资源分配.
• 在真实数据集上进行了大量的实验评估，验证了该方法在不同场景下的有效性和性能，并与现有方法进行了对比分析。

---

## 摘要

车联网是一种将车辆与互联网相连的技术，它可以提供各种智能化的服务，如导航、娱乐、安全等。然而，车辆的计算能力和能源有限，无法满足复杂和耗时的任务的需求。为了解决这个问题，车辆可以将部分任务卸载到边缘服务器上，从而节省能耗和提高性能。然而，任务卸载的过程涉及到多个车辆和多个服务器之间的协作和竞争，如何有效地分配任务和资源，是一个具有挑战性的问题。本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文还开发了一个基于 Python 的开源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。本文通过在该环境中进行一系列的仿真实验，验证了本文方法的有效性和优越性。

## 引言

车联网是一种将车辆与互联网相连的技术，它可以提供各种智能化的服务，如导航、娱乐、安全等。随着车辆的智能化和网络化的发展，车辆的计算需求也越来越高，例如，车辆可能需要进行高清视频的处理、复杂的路径规划、大规模的数据分析等。然而，车辆的计算能力和能源有限，无法满足这些复杂和耗时的任务的需求。为了解决这个问题，车辆可以将部分任务卸载到边缘服务器上，从而节省能耗和提高性能。边缘服务器是一种靠近用户的计算设备，它可以提供更快的响应时间和更高的服务质量，相比于远程的云服务器，它更适合车联网的场景。

任务卸载的过程涉及到多个车辆和多个服务器之间的协作和竞争，如何有效地分配任务和资源，是一个具有挑战性的问题。一方面，车辆需要根据自己的资源需求、连接限制和预算，选择是否将任务卸载到边缘服务器上，以及选择哪些服务器进行任务卸载，并支付相应的费用。另一方面，服务器需要根据自己的资源状况和成本，对收到的任务卸载请求进行报价，并执行被接受的任务。这样，车辆和服务器之间就形成了一个多方参与的动态的市场，它需要一个合理的机制来协调和激励各方的行为，从而实现任务卸载的效率和公平。

本文提出了一种基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以让车辆和服务器之间通过反向拍卖的方式进行任务卸载的交易，同时利用强化学习的方法来学习和优化各自的报价策略，从而实现任务卸载的效率和公平。本文的主要贡献和创新点如下：

- 本文提出了一个基于多智能体强化学习和反向拍卖机制的车联网任务卸载方法（RATO），它可以有效地解决车辆和服务器之间的任务卸载问题，提高车辆的效用和服务器的收入，同时保证负载均衡和任务完成率。
- 本文设计了一个基于 PPO+LSTM 的报价策略，它可以利用 LSTM 的记忆能力，捕捉任务卸载的时序特征和长期依赖，从而提高报价策略的性能和效果。
- 本文开发了一个基于 Python 的开源仿真环境 —— VehicleJobScheduling，它可以模拟车辆任务卸载的过程，并提供一些常用的评估指标。本文通过在该环境中进行一系列的仿真实验，验证了本文方法的有效性和优越性。

本文的结构如下：第二节介绍了相关工作；第三节介绍了问题的建模和方法的原理；第四节介绍了仿真环境的设计和参数设置；第五节介绍了实验结果和分析；第六节总结了本文的结论和展望。
